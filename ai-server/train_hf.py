import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets
from pathlib import Path
import albumentations as A
from albumentations.pytorch import ToTensorV2
import numpy as np
from transformers import AutoModelForImageClassification

# ==========================================
# 1. ì„¤ì • (ëª¨ë¸ëª…ë§Œ B2ë¡œ ë³€ê²½)
# ==========================================
CONFIG = {
    "train_dir": Path(r"D:\ahy\Projects\meathub\Meat_A_Eye-aimodels\data\dataset_final\train"),
    "val_dir":   Path(r"D:\ahy\Projects\meathub\Meat_A_Eye-aimodels\data\dataset_final\val"),
    "test_dir":  Path(r"D:\ahy\Projects\meathub\Meat_A_Eye-aimodels\data\dataset_final\test"),
    
    # â˜… HFì— ë“±ë¡ëœ EfficientNet-B2 ëª¨ë¸ (google ê³µì‹)
    "hf_model_name": "google/efficientnet-b2", 
    "model_save_path": Path(__file__).parent / "models" / "models_b2" / "meat_vision_b2_hf.pth",
    
    "num_epochs": 10,
    "batch_size": 32,        # B2ëŠ” ViTë³´ë‹¤ ê°€ë²¼ì›Œì„œ ë°°ì¹˜ë¥¼ ë” í¬ê²Œ ì¡ìœ¼ì…”ë„ ë©ë‹ˆë‹¤.
    "learning_rate": 1e-4,   # CNNì€ ViTë³´ë‹¤ ì¡°ê¸ˆ ë” ê³µê²©ì ìœ¼ë¡œ ë°°ì›Œë„ ë©ë‹ˆë‹¤.
    "image_size": 260,       # B2ì˜ í‘œì¤€ í•´ìƒë„
    "num_workers": 0,
}

# 

# ==========================================
# 2. ë°ì´í„° ì¦ê°• (B2 ìµœì í™”)
# ==========================================
train_transform = A.Compose([
    A.Resize(CONFIG["image_size"], CONFIG["image_size"]),
    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),
    A.CLAHE(clip_limit=4.0, p=0.5),
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.3),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # ImageNet í‘œì¤€
    ToTensorV2(),
])

# (AlbumentationsDataset, evaluate í•¨ìˆ˜ëŠ” ViT ë•Œì™€ ë™ì¼í•˜ë¯€ë¡œ ìƒëµ ê°€ëŠ¥í•˜ë‚˜ ì „ì²´ ì½”ë“œ ìœ„í•´ ìœ ì§€)
class AlbumentationsDataset(torch.utils.data.Dataset):
    def __init__(self, dataset, transform=None):
        self.dataset = dataset
        self.transform = transform
    def __len__(self): return len(self.dataset)
    def __getitem__(self, idx):
        image, label = self.dataset[idx]
        image = np.array(image)
        if self.transform: image = self.transform(image=image)["image"]
        return image, label

def evaluate(model, dataloader, device):
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images).logits
            _, pred = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (pred == labels).sum().item()
    return correct / total

# ==========================================
# 3. ë©”ì¸ ì‹¤í–‰
# ==========================================
def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ B2-HF Meat Vision Start | Device: {device}")

    train_raw = datasets.ImageFolder(root=CONFIG["train_dir"])
    val_raw = datasets.ImageFolder(root=CONFIG["val_dir"])
    test_raw = datasets.ImageFolder(root=CONFIG["test_dir"])
    num_classes = len(train_raw.classes)

    train_loader = DataLoader(AlbumentationsDataset(train_raw, train_transform), batch_size=CONFIG["batch_size"], shuffle=True)
    val_loader = DataLoader(AlbumentationsDataset(val_raw, train_transform), batch_size=CONFIG["batch_size"], shuffle=False)
    test_loader = DataLoader(AlbumentationsDataset(test_raw, train_transform), batch_size=CONFIG["batch_size"], shuffle=False)

    # ëª¨ë¸ ë¡œë“œ (B2 ëª¨ë¸ì„ HF ë°©ì‹ìœ¼ë¡œ ë¶ˆëŸ¬ì˜´)
    model = AutoModelForImageClassification.from_pretrained(
        CONFIG["hf_model_name"], 
        num_labels=num_classes,
        ignore_mismatched_sizes=True
    )
    model = model.to(device)

    if CONFIG["model_save_path"].exists():
        print("ğŸ”„ ê¸°ì¡´ B2 ê°€ì¤‘ì¹˜ë¥¼ ì´ì–´ì„œ í•™ìŠµí•©ë‹ˆë‹¤.")
        model.load_state_dict(torch.load(CONFIG["model_save_path"], map_location=device))

    optimizer = optim.AdamW(model.parameters(), lr=CONFIG["learning_rate"])
    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

    best_acc = 0.0
    for epoch in range(CONFIG["num_epochs"]):
        model.train()
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images).logits
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
        
        v_acc = evaluate(model, val_loader, device)
        print(f"Epoch [{epoch+1}/10] Val Acc: {v_acc:.4f}")
        if v_acc > best_acc:
            best_acc = v_acc
            torch.save(model.state_dict(), CONFIG["model_save_path"])
            print("  ğŸ”¥ B2-HF Best Saved!")

    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    model.load_state_dict(torch.load(CONFIG["model_save_path"]))
    test_acc = evaluate(model, test_loader, device)
    print(f"ğŸ† B2-HF ìµœì¢… ìˆ˜ëŠ¥ ì ìˆ˜: {test_acc*100:.2f}%")

if __name__ == "__main__":
    main()