import torch
import torch.nn as nn
from torchvision import models, transforms
import cv2
import numpy as np
import os
from pathlib import Path
from PIL import Image

# ==========================================
# 0. í•œê¸€ ê²½ë¡œ ì§€ì›ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
# ==========================================
def imread_kor(path):
    """í•œê¸€ ê²½ë¡œì˜ ì´ë¯¸ì§€ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤."""
    try:
        img_array = np.fromfile(str(path), np.uint8)
        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
        return img
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ì½ê¸° ì‹¤íŒ¨: {path} ({e})")
        return None

def imwrite_kor(path, img):
    """ì´ë¯¸ì§€ë¥¼ í•œê¸€ ê²½ë¡œì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        ext = os.path.splitext(path)[1]
        result, n = cv2.imencode(ext, img)
        if result:
            with open(path, mode='w+b') as f:
                n.tofile(f)
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {path} ({e})")

# ==========================================
# 1. ì„¤ì • (Configuration)
# ==========================================
CONFIG = {
    # [ì¤‘ìš”] í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ê°€ ë“¤ì–´ìˆëŠ” ìµœìƒìœ„ í´ë” (pork_final/test ê²½ë¡œë¡œ ì§€ì •)
    "test_root_dirs": [
        Path(r"D:\ahy\Projects\meathub\Meat_A_Eye-aimodels\data\Pork_Test2")
    ],
    
    # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
    "model_path": Path(r"D:\ahy\Projects\meathub\Meat_A_Eye-aimodels\ai-server\models\models_each\meat_vision_b2_pork.pth"),
    
    # ê²°ê³¼ê°€ ì €ì¥ë  í´ë”
    "result_save_dir": Path(r"D:\ahy\Projects\meathub\Meat_A_Eye-aimodels\pork_results"),
    
    # í´ë˜ìŠ¤ ì´ë¦„ (í´ë” ì´ë¦„ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•¨)
    "class_names": sorted([
        'Pork_Belly', 'Pork_Ham', 'Pork_Loin', 'Pork_Neck', 'Pork_PicnicShoulder',
        'Pork_Ribs', 'Pork_Tenderloin'
    ]),
    
    "image_size": 260,
    "device": torch.device("cuda" if torch.cuda.is_available() else "cpu")
}

os.makedirs(CONFIG["result_save_dir"], exist_ok=True)

# ==========================================
# 2. Grad-CAM í´ë˜ìŠ¤
# ==========================================
class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.output = None
        self.target_layer.register_forward_hook(self.save_output)
        self.target_layer.register_full_backward_hook(self.save_gradient)

    def save_output(self, module, input, output): self.output = output
    def save_gradient(self, module, grad_input, grad_output): self.gradients = grad_output[0]

    def generate(self, input_tensor, class_idx):
        self.model.zero_grad()
        output = self.model(input_tensor)
        loss = output[0, class_idx]
        loss.backward()
        
        weights = torch.mean(self.gradients, dim=(2, 3), keepdim=True)
        heatmap = torch.sum(weights * self.output, dim=1).squeeze()
        heatmap = np.maximum(heatmap.detach().cpu().numpy(), 0)
        
        # heatmap ì •ê·œí™” (0~1)
        heatmap = heatmap / (np.max(heatmap) + 1e-7)
        return heatmap

# ==========================================
# 3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë¡œì§
# ==========================================
def run_integrated_visualization():
    print(f"ğŸš€ [í´ë”ëª… ê¸°ì¤€] ì‹œê°í™” í…ŒìŠ¤íŠ¸ ì‹œì‘ (Device: {CONFIG['device']})")
    
    # 1. ëª¨ë¸ ë¡œë“œ ë° ì´ˆê¸°í™”
    try:
        model = models.efficientnet_b2(weights=None)
        # ë§ˆì§€ë§‰ ë ˆì´ì–´ ìˆ˜ì • (í´ë˜ìŠ¤ ê°œìˆ˜ì— ë§ê²Œ)
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(CONFIG["class_names"]))
        
        if not CONFIG["model_path"].exists():
            print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {CONFIG['model_path']}")
            return

        model.load_state_dict(torch.load(CONFIG["model_path"], map_location=CONFIG["device"]))
        model.to(CONFIG["device"]).eval()
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        return

    # Grad-CAM ì„¤ì • (EfficientNetì˜ ë§ˆì§€ë§‰ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´)
    grad_cam = GradCAM(model, model.features[-1])
    
    transform = transforms.Compose([
        transforms.Resize((CONFIG["image_size"], CONFIG["image_size"])),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # 2. ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘
    image_paths = []
    for root in CONFIG["test_root_dirs"]:
        if root.exists():
            # ëª¨ë“  í•˜ìœ„ í´ë”ë¥¼ ë’¤ì ¸ì„œ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
            found = list(root.rglob("*"))
            image_paths.extend([p for p in found if p.suffix.lower() in [".jpg", ".png", ".jpeg", ".bmp", ".webp"]])
    
    print(f"ğŸ” ì´ {len(image_paths)}ê°œì˜ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
    
    if not image_paths:
        print("âš ï¸ ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    # 3. ê°œë³„ ì´ë¯¸ì§€ ì²˜ë¦¬
    success_count = 0
    
    for img_path in image_paths:
        # ğŸ”¥ [í•µì‹¬ ìˆ˜ì •] ì •ë‹µ(Ground Truth)ì„ "ìƒìœ„ í´ë” ì´ë¦„"ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        # ì˜ˆ: .../test/Pork_Belly/image.jpg -> folder_name = "Pork_Belly"
        folder_name = img_path.parent.name
        
        # í´ë” ì´ë¦„ì´ ìš°ë¦¬ê°€ ì•„ëŠ” í´ë˜ìŠ¤ ëª©ë¡ì— ìˆëŠ”ì§€ í™•ì¸
        if folder_name in CONFIG["class_names"]:
            ground_truth = folder_name
        else:
            # í´ë”ëª…ì´ í´ë˜ìŠ¤ ëª©ë¡ì— ì—†ë‹¤ë©´ (ì˜ˆ: test í´ë” ë°”ë¡œ ì•„ë˜ì— íŒŒì¼ì´ ìˆëŠ” ê²½ìš° ë“±)
            print(f"âš ï¸ ê²½ê³ : '{img_path.name}'ì˜ í´ë”ëª…({folder_name})ì´ í´ë˜ìŠ¤ ëª©ë¡ì— ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        # ì´ë¯¸ì§€ ì½ê¸°
        raw_img = imread_kor(img_path)
        if raw_img is None:
            continue
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        img_rgb = cv2.cvtColor(raw_img, cv2.COLOR_BGR2RGB)
        input_tensor = transform(Image.fromarray(img_rgb)).unsqueeze(0).to(CONFIG["device"])
        
        # ì¶”ë¡  (Prediction)
        outputs = model(input_tensor)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)
        conf, pred_idx = torch.max(probabilities, 1)
        
        pred_label = CONFIG["class_names"][pred_idx.item()]
        confidence = conf.item() * 100
        
        # Grad-CAM Heatmap ìƒì„±
        heatmap = grad_cam.generate(input_tensor, pred_idx.item())
        
        # ì‹œê°í™” í•©ì„±
        view_img = cv2.resize(raw_img, (CONFIG["image_size"], CONFIG["image_size"]))
        heatmap_resize = cv2.resize(heatmap, (CONFIG["image_size"], CONFIG["image_size"]))
        
        # íˆíŠ¸ë§µ ì»¬ëŸ¬ ì…íˆê¸° (íŒŒë€ìƒ‰ -> ë¹¨ê°„ìƒ‰)
        heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap_resize), cv2.COLORMAP_JET)
        
        # ì›ë³¸ ì´ë¯¸ì§€ì™€ ê²¹ì¹˜ê¸° (íˆ¬ëª…ë„ ì¡°ì ˆ)
        blended = cv2.addWeighted(view_img, 0.6, heatmap_color, 0.4, 0)
        
        # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± (í•˜ë‹¨ì— ê²€ì€ìƒ‰ ë°” ì¶”ê°€)
        result_img = cv2.copyMakeBorder(blended, 0, 120, 0, 0, cv2.BORDER_CONSTANT, value=(0, 0, 0))
        
        # ì •ë‹µ ì—¬ë¶€ì— ë”°ë¥¸ í…ìŠ¤íŠ¸ ìƒ‰ìƒ ê²°ì •
        is_correct = (pred_label == ground_truth)
        status_color = (0, 255, 0) if is_correct else (0, 0, 255) # ë§ìœ¼ë©´ ì´ˆë¡, í‹€ë¦¬ë©´ ë¹¨ê°•
        
        # í…ìŠ¤íŠ¸ ì •ë³´ ì…ë ¥
        # (ì¢Œí‘œëŠ” ì´ë¯¸ì§€ í¬ê¸°ì— ë”°ë¼ ìœ ë™ì ì¼ ìˆ˜ ìˆìœ¼ë‚˜ ì—¬ê¸°ì„  ê³ ì •ê°’ ì‚¬ìš©)
        base_y = CONFIG["image_size"] + 25
        cv2.putText(result_img, f"GT   : {ground_truth}", (10, base_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(result_img, f"PRED : {pred_label}", (10, base_y + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, status_color, 2)
        cv2.putText(result_img, f"CONF : {confidence:.2f}%", (10, base_y + 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, status_color, 1)
        
        # íŒŒì¼ëª… í•œê¸€ ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ ì˜ì–´/ìˆ«ìë¡œë§Œ ì €ì¥í•˜ê±°ë‚˜ ì•ˆì „í•œ ì´ë¦„ ì‚¬ìš©
        # ì˜ˆ: O_Pork_Belly_image123.jpg
        safe_filename = img_path.name
        save_name = f"{'O' if is_correct else 'X'}_{ground_truth}_{safe_filename}"
        save_path = str(CONFIG["result_save_dir"] / save_name)
        
        imwrite_kor(save_path, result_img)
        success_count += 1

    print(f"\nâœ¨ ë¶„ì„ ì™„ë£Œ! ì´ {success_count}ì¥ì˜ ê²°ê³¼ ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“ ê²°ê³¼ ìœ„ì¹˜: {CONFIG['result_save_dir']}")

if __name__ == "__main__":
    run_integrated_visualization()