import torch
import torch.nn as nn
from torchvision import models, transforms
import cv2
import numpy as np
from PIL import Image
import os
import glob
from pathlib import Path

# 1. ì„¤ì • (B2 ìµœì í™”)
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

BASE_DIR = Path(__file__).resolve().parent
MODEL_PATH = BASE_DIR / "models" / "meat_vision_b2_pro.pth"
# dataset_final/test ì „ì²´(í´ë˜ìŠ¤ë³„ í´ë” í¬í•¨)ë¥¼ ì‹œê°í™” ëŒ€ìƒìœ¼ë¡œ ì‚¬ìš©
TEST_IMAGE_DIR = BASE_DIR.parent / "data" / "dataset_final" / "test"
RESULT_DIR = BASE_DIR / "test_results"

# í•™ìŠµ ì‹œ ì‚¬ìš©í•œ í´ë” ìˆœì„œì™€ ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
CLASS_NAMES = ['Beef_BottomRound', 'Beef_Brisket', 'Beef_Chuck', 'Beef_Rib', 'Beef_Ribeye', 'Beef_Round', 'Beef_Shank', 'Beef_Shoulder', 'Beef_Sirloin', 'Beef_Tenderloin']
IMAGE_SIZE = 260  # EfficientNet-B2 ê¶Œì¥ ì…ë ¥ ì‚¬ì´ì¦ˆ

os.makedirs(RESULT_DIR, exist_ok=True)

# 2. Grad-CAM í´ë˜ìŠ¤ (B2 ëŒ€ì‘)
class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.output = None

        # Hook ë“±ë¡
        self.target_layer.register_forward_hook(self.save_output)
        self.target_layer.register_full_backward_hook(self.save_gradient)

    def save_output(self, module, input, output):
        self.output = output

    def save_gradient(self, module, grad_input, grad_output):
        self.gradients = grad_output[0]

    def generate_heatmap(self, input_tensor, class_idx):
        self.model.zero_grad()
        output = self.model(input_tensor)
        
        # íƒ€ê²Ÿ í´ë˜ìŠ¤ì— ëŒ€í•œ ì—­ì „íŒŒ
        loss = output[0, class_idx]
        loss.backward()

        # ê·¸ë˜ë””ì–¸íŠ¸ í‰ê·  ê³„ì‚° (Global Average Pooling)
        weights = torch.mean(self.gradients, dim=(2, 3), keepdim=True)
        
        # ê°€ì¤‘ì¹˜ì™€ íŠ¹ì„± ë§µ ê²°í•©
        heatmap = torch.sum(weights * self.output, dim=1).squeeze()
        
        # ReLU ì ìš© ë° ì •ê·œí™”
        heatmap = np.maximum(heatmap.detach().cpu().numpy(), 0)
        heatmap /= np.max(heatmap) if np.max(heatmap) != 0 else 1
        return heatmap

# 3. B2 ëª¨ë¸ ë¡œë“œ ë° ì„¤ì •
def load_b2_model(num_classes):
    model = models.efficientnet_b2(weights=None)
    # ë¶„ë¥˜ í—¤ë“œ ìˆ˜ì • (B0ì™€ ì¸ë±ìŠ¤ êµ¬ì¡° ë™ì¼)
    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
    
    # ê°€ì¤‘ì¹˜ ë¡œë“œ
    state_dict = torch.load(str(MODEL_PATH), map_location=DEVICE)
    model.load_state_dict(state_dict)
    model.to(DEVICE).eval()
    return model

model = load_b2_model(len(CLASS_NAMES))

# B2ì˜ ë§ˆì§€ë§‰ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì„ íƒ (featuresì˜ ë§ˆì§€ë§‰ ë¸”ë¡)
target_layer = model.features[-1]
grad_cam = GradCAM(model, target_layer)

# B2 ê·œê²© ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

def run_visual_test():
    # test/ í•˜ìœ„ì˜ ëª¨ë“  ì´ë¯¸ì§€(í´ë˜ìŠ¤ë³„ í´ë” í¬í•¨)ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•¨
    image_files = glob.glob(str(TEST_IMAGE_DIR / "**" / "*.*"), recursive=True)
    print(f"ğŸš€ í…ŒìŠ¤íŠ¸ ì‹œì‘: {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ ê°ì§€ë¨ (B2 ì—”ì§„)")
    
    for img_path in image_files:
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
        raw_img = cv2.imread(img_path)
        if raw_img is None: continue
        
        raw_img_rgb = cv2.cvtColor(raw_img, cv2.COLOR_BGR2RGB)
        img_resized = cv2.resize(raw_img_rgb, (IMAGE_SIZE, IMAGE_SIZE))
        
        input_tensor = transform(Image.fromarray(img_resized)).unsqueeze(0).to(DEVICE)
        
        # 1. ì¶”ë¡  (Inference)
        with torch.set_grad_enabled(True): # Grad-CAMì„ ìœ„í•´ grad í™œì„±í™”
            output = model(input_tensor)
            prob = torch.nn.functional.softmax(output, dim=1)
            conf, pred = torch.max(prob, 1)
            class_idx = pred.item()
        
        # 2. íˆíŠ¸ë§µ ìƒì„±
        heatmap = grad_cam.generate_heatmap(input_tensor, class_idx)
        heatmap = cv2.resize(heatmap, (IMAGE_SIZE, IMAGE_SIZE))
        heatmap = np.uint8(255 * heatmap)
        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
        
        # 3. ì›ë³¸ ì´ë¯¸ì§€(260px)ì™€ íˆíŠ¸ë§µ í•©ì„±
        result_img = cv2.addWeighted(img_resized, 0.6, heatmap, 0.4, 0)
        
        # ê²°ê³¼ ì €ì¥ ë¡œì§
        filename = os.path.basename(img_path)
        save_path = os.path.join(RESULT_DIR, f"res_b2_{filename}")
        
        # ì •ë³´ í…ìŠ¤íŠ¸ ì‚½ì…
        label_text = CLASS_NAMES[class_idx]
        confidence_text = f"{conf.item()*100:.1f}%"
        display_text = f"{label_text} ({confidence_text})"
        
        # ê°€ë…ì„±ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ë°°ê²½ ì²˜ë¦¬
        cv2.rectangle(result_img, (0, 0), (260, 30), (0, 0, 0), -1)
        cv2.putText(result_img, display_text, (5, 20), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)
        
        # RGBì—ì„œ BGRë¡œ ë‹¤ì‹œ ë³€ê²½í•˜ì—¬ ì €ì¥
        cv2.imwrite(save_path, cv2.cvtColor(result_img, cv2.COLOR_RGB2BGR))
        print(f"âœ… ë¶„ì„ ì™„ë£Œ ({label_text}): {save_path}")

        del input_tensor, output, heatmap, result_img
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

if __name__ == "__main__":
    run_visual_test()