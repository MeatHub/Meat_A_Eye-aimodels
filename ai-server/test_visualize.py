import torch
import torch.nn as nn
from torchvision import models, transforms
import cv2
import numpy as np
import os
from pathlib import Path
from PIL import Image

# ==========================================
# 1. ì„¤ì • (Configuration)
# ==========================================
CONFIG = {
    # â˜… ì‹¤ì œ í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ê°€ ë“¤ì–´ìˆëŠ” í´ë”
    "test_images_dir": Path(r"D:\ahy\Projects\meathub\Meat_A_Eye-aimodels\data\test_images"),
    
    # â˜… ë°©ê¸ˆ í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ê²½ë¡œ
    "model_path": Path(r"D:\ahy\Projects\meathub\Meat_A_Eye-aimodels\ai-server\models\models_b2\meat_vision_b2_hard.pth"),
    
    # â˜… ê²°ê³¼ ì´ë¯¸ì§€ê°€ ì €ì¥ë  í´ë”
    "result_save_dir": Path(r"D:\ahy\Projects\meathub\Meat_A_Eye-aimodels\test_results"),
    
    # í•™ìŠµëœ í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ìˆœì„œê°€ ì •í™•í•´ì•¼ í•©ë‹ˆë‹¤)
    "class_names": [
        'Beef_BottomRound', 'Beef_Brisket', 'Beef_Chuck', 'Beef_Rib', 
        'Beef_Round', 'Beef_Shank', 'Beef_Shoulder', 'Beef_Sirloin', 'Beef_Tenderloin'
    ],
    
    "image_size": 260,
    "device": torch.device("cuda" if torch.cuda.is_available() else "cpu")
}

# ê²°ê³¼ ì €ì¥ í´ë” ìƒì„±
os.makedirs(CONFIG["result_save_dir"], exist_ok=True)

# ==========================================
# 2. Grad-CAM í´ë˜ìŠ¤
# ==========================================
class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.output = None
        
        # í›…(Hook) ë“±ë¡
        target_layer.register_forward_hook(self.save_output)
        target_layer.register_full_backward_hook(self.save_gradient)

    def save_output(self, module, input, output):
        self.output = output

    def save_gradient(self, module, grad_input, grad_output):
        self.gradients = grad_output[0]

    def generate(self, input_tensor, class_idx):
        self.model.zero_grad()
        output = self.model(input_tensor)
        
        # íŠ¹ì • í´ë˜ìŠ¤ì— ëŒ€í•œ ì—­ì „íŒŒ
        loss = output[0, class_idx]
        loss.backward()
        
        # ê°€ì¤‘ì¹˜ ê³„ì‚° ë° íˆíŠ¸ë§µ ìƒì„±
        weights = torch.mean(self.gradients, dim=(2, 3), keepdim=True)
        heatmap = torch.sum(weights * self.output, dim=1).squeeze()
        
        # ReLU ì ìš© ë° ì •ê·œí™”
        heatmap = np.maximum(heatmap.detach().cpu().numpy(), 0)
        heatmap = heatmap / (np.max(heatmap) + 1e-7)
        return heatmap

# ==========================================
# 3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë¡œì§
# ==========================================
def run_visualization():
    print(f"ğŸš€ ì‹œê°í™” í…ŒìŠ¤íŠ¸ ì‹œì‘ (Device: {CONFIG['device']})")
    
    # 1. ëª¨ë¸ ë¡œë“œ
    model = models.efficientnet_b2(weights=None)
    model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(CONFIG["class_names"]))
    
    if not CONFIG["model_path"].exists():
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {CONFIG['model_path']}")
        return
        
    model.load_state_dict(torch.load(CONFIG["model_path"], map_location=CONFIG["device"]))
    model.to(CONFIG["device"]).eval()

    # 2. Grad-CAM ì¤€ë¹„ (EfficientNet-B2ì˜ ë§ˆì§€ë§‰ íŠ¹ì§• ë§µ ì¶”ì¶œ ì¸µ)
    target_layer = model.features[-1]
    grad_cam = GradCAM(model, target_layer)

    # 3. ì „ì²˜ë¦¬ ì •ì˜
    transform = transforms.Compose([
        transforms.Resize((CONFIG["image_size"], CONFIG["image_size"])),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # 4. ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    image_paths = [p for p in CONFIG["test_images_dir"].glob("*") if p.suffix.lower() in [".jpg", ".png", ".jpeg"]]
    print(f"ğŸ” {len(image_paths)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")

    for img_path in image_paths:
        # ì´ë¯¸ì§€ ì½ê¸°
        raw_img = cv2.imread(str(img_path))
        if raw_img is None: continue
        
        # ì „ì²˜ë¦¬
        img_rgb = cv2.cvtColor(raw_img, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(img_rgb)
        input_tensor = transform(pil_img).unsqueeze(0).to(CONFIG["device"])
        
        # ì¶”ë¡ 
        outputs = model(input_tensor)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)
        conf, pred_idx = torch.max(probabilities, 1)
        
        pred_label = CONFIG["class_names"][pred_idx.item()]
        confidence = conf.item() * 100
        
        # íˆíŠ¸ë§µ ìƒì„±
        heatmap = grad_cam.generate(input_tensor, pred_idx.item())
        
        # --- ì‹œê°í™” ê°€ê³µ ---
        # 1. ì›ë³¸ì„ ì •ì‚¬ê°í˜•ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ëª¨ë¸ì´ ë³¸ ì‹œì ê³¼ ì¼ì¹˜ì‹œí‚´)
        view_img = cv2.resize(raw_img, (CONFIG["image_size"], CONFIG["image_size"]))
        
        # 2. íˆíŠ¸ë§µì„ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ í‚¤ìš°ê³  ìƒ‰ìƒ ì…íˆê¸°
        heatmap_resize = cv2.resize(heatmap, (CONFIG["image_size"], CONFIG["image_size"]))
        heatmap_uint8 = np.uint8(255 * heatmap_resize)
        heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
        
        # 3. ì›ë³¸ê³¼ íˆíŠ¸ë§µ í•©ì„± (ì›ë³¸ 60%, íˆíŠ¸ë§µ 40%)
        blended = cv2.addWeighted(view_img, 0.6, heatmap_color, 0.4, 0)
        
        # 4. ìƒë‹¨ ì—¬ë°± ì¶”ê°€ (100px ê²€ì€ìƒ‰ ë°”) - í…ìŠ¤íŠ¸ ì˜ë¦¼ ë°©ì§€
        header_h = 100
        result_img = cv2.copyMakeBorder(blended, header_h, 0, 0, 0, cv2.BORDER_CONSTANT, value=(0, 0, 0))
        
        # 5. í…ìŠ¤íŠ¸ 2ì¤„ë¡œ ë‚˜ëˆ„ì–´ ì‘ì„± (ê°€ë¡œ ì˜ë¦¼ ë°©ì§€)
        txt_color = (0, 255, 0) # ì´ˆë¡ìƒ‰
        text_1 = f"PRED: {pred_label}"
        text_2 = f"CONF: {confidence:.2f}%"
        
        # ì²« ë²ˆì§¸ ì¤„
        cv2.putText(result_img, text_1, (15, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)
        # ë‘ ë²ˆì§¸ ì¤„
        cv2.putText(result_img, text_2, (15, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.6, txt_color, 2, cv2.LINE_AA)

        # 6. ê²°ê³¼ ì €ì¥
        save_path = CONFIG["result_save_dir"] / f"vis_{img_path.name}"
        cv2.imwrite(str(save_path), result_img)
        print(f"âœ… ì €ì¥ ì™„ë£Œ: {save_path.name} ({pred_label})")

    print(f"\nâœ¨ ëª¨ë“  ê²°ê³¼ê°€ '{CONFIG['result_save_dir']}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    run_visualization()