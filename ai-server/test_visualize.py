import torch
import torch.nn as nn
from torchvision import models, transforms
import cv2
import numpy as np
from PIL import Image
import os
import glob
from pathlib import Path
from datetime import datetime

# 1. ì„¤ì • (Mac M2: MPS ìš°ì„ , ì—†ìœ¼ë©´ CUDA â†’ CPU)
DEVICE = torch.device("mps" if getattr(torch.backends, "mps", None) and torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu")

BASE_DIR = Path(__file__).resolve().parent
MODEL_PATH = BASE_DIR / "models" / "meat_vision_b2_pro.pth"
# dataset_final/test ì „ì²´(í´ë˜ìŠ¤ë³„ í´ë” í¬í•¨)ë¥¼ ì‹œê°í™” ëŒ€ìƒìœ¼ë¡œ ì‚¬ìš©
TEST_IMAGE_DIR = BASE_DIR.parent / "data" / "dataset_final" / "test"
# ì‹¤í–‰ ì‹œê°ë³„ë¡œ ì €ì¥ â†’ "ë°©ê¸ˆ í•™ìŠµí•œ ê²°ê³¼"ë§Œ êµ¬ë¶„ ê°€ëŠ¥ (ì˜ˆ: test_results/meat_vision_b2_pro_2025-02-04_14-30-22)
RESULT_BASE = BASE_DIR / "test_results"

# True: Pork_Loin, Pork_Tenderloinë§Œ Grad-CAM (ë¹ ë¥´ê²Œ í™•ì¸ìš©) / False: test ì „ì²´
FOCUS_PORK_LOIN_TENDERLOIN = True

# í•™ìŠµ ì‹œ ì‚¬ìš©í•œ í´ë” ìˆœì„œì™€ ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. (ImageFolder ì•ŒíŒŒë²³ ìˆœ = trainê³¼ ë™ì¼)
CLASS_NAMES = [
    'Beef_BottomRound', 'Beef_Brisket', 'Beef_Chuck', 'Beef_Rib', 'Beef_Ribeye',
    'Beef_Round', 'Beef_Shank', 'Beef_Shoulder', 'Beef_Sirloin', 'Beef_Tenderloin',
    'Pork_Loin', 'Pork_Tenderloin'
]
IMAGE_SIZE = 260  # EfficientNet-B2 ê¶Œì¥ ì…ë ¥ ì‚¬ì´ì¦ˆ

# 2. Grad-CAM í´ë˜ìŠ¤ (B2 ëŒ€ì‘)
class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.output = None

        # Hook ë“±ë¡
        self.target_layer.register_forward_hook(self.save_output)
        self.target_layer.register_full_backward_hook(self.save_gradient)

    def save_output(self, module, input, output):
        self.output = output

    def save_gradient(self, module, grad_input, grad_output):
        self.gradients = grad_output[0]

    def generate_heatmap(self, input_tensor, class_idx):
        self.model.zero_grad()
        output = self.model(input_tensor)
        
        # íƒ€ê²Ÿ í´ë˜ìŠ¤ì— ëŒ€í•œ ì—­ì „íŒŒ
        loss = output[0, class_idx]
        loss.backward()

        # ê·¸ë˜ë””ì–¸íŠ¸ í‰ê·  ê³„ì‚° (Global Average Pooling)
        weights = torch.mean(self.gradients, dim=(2, 3), keepdim=True)
        
        # ê°€ì¤‘ì¹˜ì™€ íŠ¹ì„± ë§µ ê²°í•©
        heatmap = torch.sum(weights * self.output, dim=1).squeeze()
        
        # ReLU ì ìš© ë° ì •ê·œí™”
        heatmap = np.maximum(heatmap.detach().cpu().numpy(), 0)
        heatmap /= np.max(heatmap) if np.max(heatmap) != 0 else 1
        return heatmap

# 3. B2 ëª¨ë¸ ë¡œë“œ ë° ì„¤ì •
def load_b2_model(num_classes):
    model = models.efficientnet_b2(weights=None)
    # ë¶„ë¥˜ í—¤ë“œ ìˆ˜ì • (B0ì™€ ì¸ë±ìŠ¤ êµ¬ì¡° ë™ì¼)
    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
    
    # ê°€ì¤‘ì¹˜ ë¡œë“œ
    state_dict = torch.load(str(MODEL_PATH), map_location=DEVICE)
    model.load_state_dict(state_dict)
    model.to(DEVICE).eval()
    return model

model = load_b2_model(len(CLASS_NAMES))

# B2ì˜ ë§ˆì§€ë§‰ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì„ íƒ (featuresì˜ ë§ˆì§€ë§‰ ë¸”ë¡)
target_layer = model.features[-1]
grad_cam = GradCAM(model, target_layer)

# B2 ê·œê²© ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

def run_visual_test():
    # ì´ë²ˆ ì‹¤í–‰ ì „ìš© í´ë”: ëª¨ë¸ì´ë¦„_ë‚ ì§œ_ì‹œê° (ë°©ê¸ˆ í•™ìŠµí•œ ê²°ê³¼ë§Œ ë³´ê³  ì‹¶ì„ ë•Œ êµ¬ë¶„ìš©)
    model_stem = MODEL_PATH.stem  # e.g. meat_vision_b2_pro
    run_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    RESULT_DIR = RESULT_BASE / f"{model_stem}_{run_time}"
    os.makedirs(RESULT_DIR, exist_ok=True)
    print(f"ğŸ“ ê²°ê³¼ ì €ì¥ í´ë”: {RESULT_DIR}\n")

    # test/ í•˜ìœ„ ì´ë¯¸ì§€ ìˆ˜ì§‘ (FOCUS_PORK_LOIN_TENDERLOINì´ë©´ ë¼ì§€ ë“±ì‹¬Â·ì•ˆì‹¬ë§Œ)
    if FOCUS_PORK_LOIN_TENDERLOIN:
        image_files = []
        for folder in ("Pork_Loin", "Pork_Tenderloin"):
            path = TEST_IMAGE_DIR / folder
            if path.exists():
                image_files.extend(glob.glob(str(path / "*.*")))
        image_files = [f for f in image_files if f.lower().endswith((".jpg", ".jpeg", ".png"))]
        print(f"ğŸš€ Grad-CAM ì‹œì‘: ë¼ì§€ ë“±ì‹¬Â·ì•ˆì‹¬ë§Œ {len(image_files)}ê°œ (B2)")
    else:
        image_files = glob.glob(str(TEST_IMAGE_DIR / "**" / "*.*"), recursive=True)
        image_files = [f for f in image_files if f.lower().endswith((".jpg", ".jpeg", ".png"))]
        print(f"ğŸš€ Grad-CAM ì‹œì‘: test ì „ì²´ {len(image_files)}ê°œ (B2)")
    
    for img_path in image_files:
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
        raw_img = cv2.imread(img_path)
        if raw_img is None: continue
        
        raw_img_rgb = cv2.cvtColor(raw_img, cv2.COLOR_BGR2RGB)
        img_resized = cv2.resize(raw_img_rgb, (IMAGE_SIZE, IMAGE_SIZE))
        
        input_tensor = transform(Image.fromarray(img_resized)).unsqueeze(0).to(DEVICE)
        
        # 1. ì¶”ë¡  (Inference)
        with torch.set_grad_enabled(True): # Grad-CAMì„ ìœ„í•´ grad í™œì„±í™”
            output = model(input_tensor)
            prob = torch.nn.functional.softmax(output, dim=1)
            conf, pred = torch.max(prob, 1)
            class_idx = pred.item()
        
        # 2. íˆíŠ¸ë§µ ìƒì„±
        heatmap = grad_cam.generate_heatmap(input_tensor, class_idx)
        heatmap = cv2.resize(heatmap, (IMAGE_SIZE, IMAGE_SIZE))
        heatmap = np.uint8(255 * heatmap)
        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
        
        # 3. ì›ë³¸ ì´ë¯¸ì§€(260px)ì™€ íˆíŠ¸ë§µ í•©ì„±
        result_img = cv2.addWeighted(img_resized, 0.6, heatmap, 0.4, 0)
        
        # ê²°ê³¼ ì €ì¥ ë¡œì§ (RESULT_DIR = ì´ë²ˆ ì‹¤í–‰ ì‹œê° í´ë”)
        filename = os.path.basename(img_path)
        save_path = os.path.join(str(RESULT_DIR), f"res_b2_{filename}")
        
        # ì •ë³´ í…ìŠ¤íŠ¸ ì‚½ì…
        label_text = CLASS_NAMES[class_idx]
        confidence_text = f"{conf.item()*100:.1f}%"
        display_text = f"{label_text} ({confidence_text})"
        
        # ê°€ë…ì„±ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ë°°ê²½ ì²˜ë¦¬
        cv2.rectangle(result_img, (0, 0), (260, 30), (0, 0, 0), -1)
        cv2.putText(result_img, display_text, (5, 20), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)
        
        # RGBì—ì„œ BGRë¡œ ë‹¤ì‹œ ë³€ê²½í•˜ì—¬ ì €ì¥
        cv2.imwrite(save_path, cv2.cvtColor(result_img, cv2.COLOR_RGB2BGR))
        print(f"âœ… ë¶„ì„ ì™„ë£Œ ({label_text}): {save_path}")

        del input_tensor, output, heatmap, result_img
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        elif str(DEVICE) == "mps":
            torch.mps.empty_cache()

if __name__ == "__main__":
    run_visual_test()