import torch
import torch.nn as nn
from torchvision import models, transforms
import cv2
import numpy as np
from PIL import Image
import os
import glob
from tqdm import tqdm

# 1. ì„¤ì •
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_PATH = r"C:\Pyg\Projects\meathub\Meat_A_Eye-aimodels\ai-server\models\b2_imagenet_beef_100-v4.pth"
TEST_IMAGE_DIR = r"C:\Pyg\Projects\meathub\Meat_A_Eye-aimodels\data\train_dataset_0\test"  # ë¶€ìœ„ë³„ ì„œë¸Œí´ë” êµ¬ì¡°
RESULT_DIR = r"C:\Pyg\Projects\meathub\Meat_A_Eye-aimodels\test_results_v0"

CLASS_NAMES = ['Beef_Brisket', 'Beef_Chuck', 'Beef_Rib', 'Beef_Ribeye', 'Beef_Round', 'Beef_Shank', 'Beef_Shoulder', 'Beef_Sirloin', 'Beef_Tenderloin']
# 10í´ë˜ìŠ¤ ëª¨ë¸ìš© ë³‘í•© ë§¤í•‘ (9í´ë˜ìŠ¤ ëª¨ë¸ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
CLASS_MERGE_MAP = {"Beef_BottomRound": "Beef_Round"}
IMAGE_SIZE = 260

os.makedirs(RESULT_DIR, exist_ok=True)


def collect_test_images(base_dir):
    """ë¶€ìœ„ë³„ ì„œë¸Œí´ë”ì—ì„œ ëª¨ë“  ì´ë¯¸ì§€ ìˆ˜ì§‘ (ê²½ë¡œ, ì •ë‹µ í´ë˜ìŠ¤)"""
    images = []
    for class_name in CLASS_NAMES:
        # Beef_BottomRound í´ë”ë„ ìˆ˜ì§‘í•˜ë˜ ì •ë‹µì€ Beef_Roundë¡œ ë³‘í•©
        mapped_name = CLASS_MERGE_MAP.get(class_name, class_name)
        class_dir = os.path.join(base_dir, class_name)
        if not os.path.exists(class_dir):
            continue
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.webp']:
            for img_path in glob.glob(os.path.join(class_dir, ext)):
                images.append((img_path, mapped_name))
    return images

# Grad-CAM í´ë˜ìŠ¤ (B2 ëŒ€ì‘)
class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.output = None
        self.target_layer.register_forward_hook(self.save_output)
        self.target_layer.register_full_backward_hook(self.save_gradient)

    def save_output(self, module, input, output): self.output = output
    def save_gradient(self, module, grad_input, grad_output): self.gradients = grad_output[0]

    def generate_heatmap(self, input_tensor, class_idx):
        self.model.zero_grad()
        output = self.model(input_tensor)
        loss = output[0, class_idx]
        loss.backward()
        weights = torch.mean(self.gradients, dim=(2, 3), keepdim=True)
        heatmap = torch.sum(weights * self.output, dim=1).squeeze()
        heatmap = np.maximum(heatmap.detach().cpu().numpy(), 0)
        heatmap /= np.max(heatmap) if np.max(heatmap) != 0 else 1
        return heatmap

def load_b2_model(num_classes):
    model = models.efficientnet_b2(weights=None)
    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
    model.to(DEVICE).eval()
    return model

# ëª¨ë¸ ë° ì „ì²˜ë¦¬ ì„¤ì •
model = load_b2_model(len(CLASS_NAMES))
target_layer = model.features[-1]
grad_cam = GradCAM(model, target_layer)
transform = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

def run_visual_test():
    # ë¶€ìœ„ë³„ ì„œë¸Œí´ë”ì—ì„œ ì´ë¯¸ì§€ ìˆ˜ì§‘
    image_list = collect_test_images(TEST_IMAGE_DIR)
    print(f"\nğŸš€ [ë¶„ì„ ì‹œì‘] ì´ {len(image_list)}ê°œì˜ ì´ë¯¸ì§€ ê²€ì¦ ì¤‘...")
    print(f"ğŸ“‚ í…ŒìŠ¤íŠ¸ í´ë”: {TEST_IMAGE_DIR}")
    print("-" * 90)
    print(f"{'íŒŒì¼ëª…':<35} | {'ì‹¤ì œ ì •ë‹µ':<18} | {'ëª¨ë¸ ì˜ˆì¸¡':<18} | {'ì‹ ë¢°ë„':<8} | {'ê²°ê³¼'}")
    print("-" * 90)

    correct_count = 0
    total_count = 0
    
    # í´ë˜ìŠ¤ë³„ í†µê³„
    class_stats = {name: {"correct": 0, "total": 0, "wrong_preds": []} for name in CLASS_NAMES}
    
    # í´ë˜ìŠ¤ë³„ ê²°ê³¼ í´ë” ìƒì„±
    for class_name in CLASS_NAMES:
        os.makedirs(os.path.join(RESULT_DIR, class_name), exist_ok=True)
    os.makedirs(os.path.join(RESULT_DIR, "_wrong"), exist_ok=True)  # ì˜¤ë‹µ ëª¨ìŒ

    for img_path, ground_truth in image_list:
        filename = os.path.basename(img_path)
        raw_img = cv2.imread(img_path)
        if raw_img is None: continue

        # ì „ì²˜ë¦¬ ë° ì¶”ë¡ 
        raw_img_rgb = cv2.cvtColor(raw_img, cv2.COLOR_BGR2RGB)
        img_resized = cv2.resize(raw_img_rgb, (IMAGE_SIZE, IMAGE_SIZE))
        input_tensor = transform(Image.fromarray(img_resized)).unsqueeze(0).to(DEVICE)
        
        with torch.set_grad_enabled(True):
            output = model(input_tensor)
            prob = torch.nn.functional.softmax(output, dim=1)
            
            # 10í´ë˜ìŠ¤ ëª¨ë¸ì¼ ë•Œë§Œ ì„¤ë„â†’ìš°ë‘” í™•ë¥  ë³‘í•©
            if len(CLASS_NAMES) == 10:
                prob[0, 5] += prob[0, 0]  # Beef_Round += Beef_BottomRound
                prob[0, 0] = 0
            
            conf, pred = torch.max(prob, 1)
            class_idx = pred.item()
            pred_label = CLASS_NAMES[class_idx]
            pred_label = CLASS_MERGE_MAP.get(pred_label, pred_label)  # ë³‘í•© ë§¤í•‘
            confidence = conf.item()

        # ì •í™•ë„ ê³„ì‚°
        is_correct = (pred_label == ground_truth)
        if is_correct: 
            correct_count += 1
            class_stats[ground_truth]["correct"] += 1
        else:
            class_stats[ground_truth]["wrong_preds"].append((filename, pred_label, confidence))
        
        class_stats[ground_truth]["total"] += 1
        total_count += 1
        result_mark = "âœ…" if is_correct else "âŒ"

        # íˆíŠ¸ë§µ ìƒì„± ë° í•©ì„±
        heatmap = grad_cam.generate_heatmap(input_tensor, class_idx)
        heatmap = cv2.resize(heatmap, (IMAGE_SIZE, IMAGE_SIZE))
        heatmap_img = np.uint8(255 * heatmap)
        heatmap_color = cv2.applyColorMap(heatmap_img, cv2.COLORMAP_JET)
        
        # [ì›ë³¸ | ì—´ì§€ë„ | í•©ì„±ë³¸] ê°€ë¡œë¡œ ë¶™ì´ê¸°
        overlaid = cv2.addWeighted(img_resized, 0.6, heatmap_color, 0.4, 0)
        combined_view = np.hstack((img_resized, heatmap_color, overlaid))
        
        # ê²°ê³¼ ì´ë¯¸ì§€ ìƒë‹¨ì— ì •ë³´ í…ìŠ¤íŠ¸ ì¶”ê°€
        info_bar = np.zeros((50, combined_view.shape[1], 3), dtype=np.uint8)
        text = f"True: {ground_truth} | Pred: {pred_label} ({confidence*100:.1f}%)"
        color = (0, 255, 0) if is_correct else (255, 0, 0)
        cv2.putText(info_bar, text, (20, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
        final_report = np.vstack((info_bar, combined_view))

        # ì €ì¥ (í´ë˜ìŠ¤ë³„ í´ë” + ì˜¤ë‹µì€ _wrong í´ë”ì—ë„ ì €ì¥)
        save_path = os.path.join(RESULT_DIR, ground_truth, f"report_{filename}")
        cv2.imwrite(save_path, cv2.cvtColor(final_report, cv2.COLOR_RGB2BGR))
        
        if not is_correct:
            wrong_path = os.path.join(RESULT_DIR, "_wrong", f"{ground_truth}_to_{pred_label}_{filename}")
            cv2.imwrite(wrong_path, cv2.cvtColor(final_report, cv2.COLOR_RGB2BGR))
        
        print(f"{filename[:35]:<35} | {ground_truth:<18} | {pred_label:<18} | {confidence*100:>6.1f}% | {result_mark}")

    # í´ë˜ìŠ¤ë³„ ì •í™•ë„ ìš”ì•½
    print("\n" + "=" * 90)
    print("ğŸ“Š [í´ë˜ìŠ¤ë³„ ì •í™•ë„]")
    print("=" * 90)
    print(f"{'í´ë˜ìŠ¤':<22} | {'ë§ì¶¤':>6} | {'ì „ì²´':>6} | {'ì •í™•ë„':>10} | {'ì£¼ìš” ì˜¤ë¶„ë¥˜'}")
    print("-" * 90)
    
    for name in CLASS_NAMES:
        stats = class_stats[name]
        acc = (stats["correct"] / stats["total"] * 100) if stats["total"] > 0 else 0
        
        # ì£¼ìš” ì˜¤ë¶„ë¥˜ ë¶„ì„
        wrong_summary = ""
        if stats["wrong_preds"]:
            wrong_classes = {}
            for _, wrong_pred, _ in stats["wrong_preds"]:
                wrong_classes[wrong_pred] = wrong_classes.get(wrong_pred, 0) + 1
            top_wrong = sorted(wrong_classes.items(), key=lambda x: -x[1])[:2]
            wrong_summary = ", ".join([f"{k}({v})" for k, v in top_wrong])
        
        acc_bar = "â–ˆ" * int(acc // 10) + "â–‘" * (10 - int(acc // 10))
        print(f"{name:<22} | {stats['correct']:>6} | {stats['total']:>6} | {acc:>6.1f}% {acc_bar} | {wrong_summary}")

    # ìµœì¢… ìš”ì•½
    accuracy = (correct_count / total_count) * 100 if total_count > 0 else 0
    print("=" * 90)
    print(f"ğŸ“Š [ìµœì¢… ê²°ê³¼] ì „ì²´: {total_count} | ë§ì¶¤: {correct_count} | í‹€ë¦¼: {total_count-correct_count}")
    print(f"ğŸ¯ ìµœì¢… ì •í™•ë„(Accuracy): {accuracy:.2f}%")
    print("=" * 90)
    print(f"ğŸ“‚ ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥ ìœ„ì¹˜: {RESULT_DIR}")
    print(f"   - í´ë˜ìŠ¤ë³„ í´ë”: ê° ë¶€ìœ„ë³„ ê²°ê³¼")
    print(f"   - _wrong í´ë”: ì˜¤ë‹µë§Œ ëª¨ì•„ë³´ê¸°")

if __name__ == "__main__":
    run_visual_test()