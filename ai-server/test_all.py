"""
ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í†µí•© í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
train_dataset_1~N/test í´ë”ë¥¼ ëª¨ë‘ í•©ì³ì„œ í•œ ë²ˆì— í…ŒìŠ¤íŠ¸.
"""
import torch
import torch.nn as nn
from torchvision import models, transforms
import cv2
import numpy as np
from PIL import Image
import os
import glob

# ===== ì„¤ì • =====
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_PATH = r"C:\Pyg\Projects\meathub\Meat_A_Eye-aimodels\ai-server\models\b2_imagenet_beef_100-v3.pth"
DATA_ROOT = r"C:\Pyg\Projects\meathub\Meat_A_Eye-aimodels\data"
RESULT_DIR = r"C:\Pyg\Projects\meathub\Meat_A_Eye-aimodels\test_results_all"

CLASS_NAMES = ['Beef_Brisket', 'Beef_Chuck', 'Beef_Rib', 'Beef_Ribeye', 'Beef_Round',
               'Beef_Shank', 'Beef_Shoulder', 'Beef_Sirloin', 'Beef_Tenderloin']
CLASS_MERGE_MAP = {"Beef_BottomRound": "Beef_Round"}
IMAGE_SIZE = 260
SAVE_REPORTS = True   # Falseë¡œ í•˜ë©´ ì´ë¯¸ì§€ ì €ì¥ ì—†ì´ ìˆ˜ì¹˜ë§Œ ì¶œë ¥ (ë¹ ë¦„)


def find_test_dirs(data_root):
    """train_dataset_*/test í´ë”ë¥¼ ìë™ íƒìƒ‰."""
    dirs = []
    for entry in sorted(os.listdir(data_root)):
        test_dir = os.path.join(data_root, entry, "test")
        if entry.startswith("train_dataset_") and os.path.isdir(test_dir):
            dirs.append((entry, test_dir))
    return dirs


def collect_images(test_dir, dataset_name):
    """í•œ test í´ë”ì—ì„œ ì´ë¯¸ì§€ ìˆ˜ì§‘. (ê²½ë¡œ, ì •ë‹µ, ì¶œì²˜ ë°ì´í„°ì…‹)"""
    images = []
    # 9í´ë˜ìŠ¤ + BottomRound í´ë”ë„ íƒìƒ‰
    scan_classes = CLASS_NAMES + ["Beef_BottomRound"]
    for class_name in scan_classes:
        mapped = CLASS_MERGE_MAP.get(class_name, class_name)
        class_dir = os.path.join(test_dir, class_name)
        if not os.path.isdir(class_dir):
            continue
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.webp']:
            for img_path in glob.glob(os.path.join(class_dir, ext)):
                images.append((img_path, mapped, dataset_name))
    return images


# ===== Grad-CAM =====
class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.gradients = self.output = None
        target_layer.register_forward_hook(lambda m, i, o: setattr(self, 'output', o))
        target_layer.register_full_backward_hook(lambda m, gi, go: setattr(self, 'gradients', go[0]))

    def generate_heatmap(self, input_tensor, class_idx):
        self.model.zero_grad()
        out = self.model(input_tensor)
        out[0, class_idx].backward()
        w = torch.mean(self.gradients, dim=(2, 3), keepdim=True)
        hm = torch.sum(w * self.output, dim=1).squeeze()
        hm = np.maximum(hm.detach().cpu().numpy(), 0)
        hm /= (hm.max() + 1e-8)
        return hm


def load_model(num_classes):
    model = models.efficientnet_b2(weights=None)
    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
    model.to(DEVICE).eval()
    return model


def run_all_tests():
    # ëª¨ë¸ ë¡œë“œ
    model = load_model(len(CLASS_NAMES))
    grad_cam = GradCAM(model, model.features[-1])
    transform = transforms.Compose([
        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # test í´ë” íƒìƒ‰
    test_dirs = find_test_dirs(DATA_ROOT)
    if not test_dirs:
        print("âŒ test í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\n{'='*100}")
    print(f"ğŸ” í†µí•© í…ŒìŠ¤íŠ¸ â€” ëª¨ë¸: {os.path.basename(MODEL_PATH)}")
    print(f"{'='*100}")
    print(f"  ë°œê²¬ëœ í…ŒìŠ¤íŠ¸ í´ë”:")
    for name, path in test_dirs:
        print(f"    ğŸ“‚ {name}/test")

    # ì „ì²´ ì´ë¯¸ì§€ ìˆ˜ì§‘
    all_images = []
    for name, path in test_dirs:
        imgs = collect_images(path, name)
        all_images.extend(imgs)
        print(f"    â†’ {name}: {len(imgs)}ê°œ")
    print(f"  ì´ ì´ë¯¸ì§€: {len(all_images)}ê°œ\n")

    # ê²°ê³¼ í´ë” ìƒì„±
    if SAVE_REPORTS:
        os.makedirs(RESULT_DIR, exist_ok=True)
        for cn in CLASS_NAMES:
            os.makedirs(os.path.join(RESULT_DIR, cn), exist_ok=True)
        os.makedirs(os.path.join(RESULT_DIR, "_wrong"), exist_ok=True)

    # â”€â”€ í†µê³„ìš© êµ¬ì¡° â”€â”€
    # ì „ì²´ í†µê³„
    total_correct, total_count = 0, 0
    class_stats = {n: {"correct": 0, "total": 0, "wrong_preds": []} for n in CLASS_NAMES}

    # ë°ì´í„°ì…‹ë³„ í†µê³„
    ds_stats = {}
    for name, _ in test_dirs:
        ds_stats[name] = {
            "correct": 0, "total": 0,
            "class_stats": {n: {"correct": 0, "total": 0, "wrong_preds": []} for n in CLASS_NAMES}
        }

    # â”€â”€ ì¶”ë¡  â”€â”€
    print("-" * 100)
    print(f"{'ë°ì´í„°ì…‹':<18} | {'íŒŒì¼ëª…':<30} | {'ì •ë‹µ':<18} | {'ì˜ˆì¸¡':<18} | {'ì‹ ë¢°ë„':<8} | {'ê²°ê³¼'}")
    print("-" * 100)

    for img_path, ground_truth, ds_name in all_images:
        filename = os.path.basename(img_path)
        raw_img = cv2.imread(img_path)
        if raw_img is None:
            continue

        raw_img_rgb = cv2.cvtColor(raw_img, cv2.COLOR_BGR2RGB)
        img_resized = cv2.resize(raw_img_rgb, (IMAGE_SIZE, IMAGE_SIZE))
        input_tensor = transform(Image.fromarray(img_resized)).unsqueeze(0).to(DEVICE)

        with torch.set_grad_enabled(SAVE_REPORTS):
            output = model(input_tensor)
            prob = torch.nn.functional.softmax(output, dim=1)

            # 10í´ë˜ìŠ¤ ëª¨ë¸ì´ë©´ ë³‘í•©
            if len(CLASS_NAMES) == 10:
                prob[0, 5] += prob[0, 0]
                prob[0, 0] = 0

            conf, pred = torch.max(prob, 1)
            class_idx = pred.item()
            pred_label = CLASS_NAMES[class_idx]
            pred_label = CLASS_MERGE_MAP.get(pred_label, pred_label)
            confidence = conf.item()

        is_correct = pred_label == ground_truth
        mark = "âœ…" if is_correct else "âŒ"

        # ì „ì²´ í†µê³„
        total_count += 1
        if is_correct:
            total_correct += 1
            class_stats[ground_truth]["correct"] += 1
        else:
            class_stats[ground_truth]["wrong_preds"].append((filename, pred_label, confidence, ds_name))
        class_stats[ground_truth]["total"] += 1

        # ë°ì´í„°ì…‹ë³„ í†µê³„
        ds = ds_stats[ds_name]
        ds["total"] += 1
        if is_correct:
            ds["correct"] += 1
            ds["class_stats"][ground_truth]["correct"] += 1
        else:
            ds["class_stats"][ground_truth]["wrong_preds"].append((filename, pred_label, confidence))
        ds["class_stats"][ground_truth]["total"] += 1

        # ë¦¬í¬íŠ¸ ì´ë¯¸ì§€ ì €ì¥
        if SAVE_REPORTS:
            heatmap = grad_cam.generate_heatmap(input_tensor, class_idx)
            heatmap = cv2.resize(heatmap, (IMAGE_SIZE, IMAGE_SIZE))
            hmc = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)
            ov = cv2.addWeighted(img_resized, 0.6, hmc, 0.4, 0)
            combined = np.hstack((img_resized, hmc, ov))

            bar = np.zeros((50, combined.shape[1], 3), dtype=np.uint8)
            txt = f"[{ds_name}] True: {ground_truth} | Pred: {pred_label} ({confidence*100:.1f}%)"
            cv2.putText(bar, txt, (10, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.65,
                        (0, 255, 0) if is_correct else (255, 0, 0), 2)
            final = np.vstack((bar, combined))
            final_bgr = cv2.cvtColor(final, cv2.COLOR_RGB2BGR)

            cv2.imwrite(os.path.join(RESULT_DIR, ground_truth, f"{ds_name}_{filename}"), final_bgr)
            if not is_correct:
                cv2.imwrite(os.path.join(RESULT_DIR, "_wrong",
                            f"{ds_name}_{ground_truth}_to_{pred_label}_{filename}"), final_bgr)

        print(f"{ds_name:<18} | {filename[:30]:<30} | {ground_truth:<18} | {pred_label:<18} | {confidence*100:>6.1f}% | {mark}")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ê²°ê³¼ ìš”ì•½
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    # 1) ë°ì´í„°ì…‹ë³„ ì •í™•ë„ ë¹„êµ
    print("\n" + "=" * 100)
    print("ğŸ“Š [ë°ì´í„°ì…‹ë³„ ì •í™•ë„ ë¹„êµ]")
    print("=" * 100)
    print(f"  {'ë°ì´í„°ì…‹':<22} | {'ë§ì¶¤':>6} | {'ì „ì²´':>6} | {'ì •í™•ë„':>10}")
    print(f"  {'-'*22}-+-{'-'*6}-+-{'-'*6}-+-{'-'*10}")

    for name, _ in test_dirs:
        ds = ds_stats[name]
        acc = ds["correct"] / ds["total"] * 100 if ds["total"] else 0
        bar = "â–ˆ" * int(acc // 10) + "â–‘" * (10 - int(acc // 10))
        print(f"  {name:<22} | {ds['correct']:>6} | {ds['total']:>6} | {acc:>6.1f}% {bar}")

    total_acc = total_correct / total_count * 100 if total_count else 0
    print(f"  {'-'*22}-+-{'-'*6}-+-{'-'*6}-+-{'-'*10}")
    print(f"  {'í•©ê³„':<22} | {total_correct:>6} | {total_count:>6} | {total_acc:>6.1f}%")

    # 2) ë°ì´í„°ì…‹ë³„ ì„¸ë¶€ í´ë˜ìŠ¤ í…Œì´ë¸”
    for name, _ in test_dirs:
        ds = ds_stats[name]
        ds_acc = ds["correct"] / ds["total"] * 100 if ds["total"] else 0
        print(f"\n  â”€â”€ {name} (ì •í™•ë„: {ds_acc:.1f}%) â”€â”€")
        print(f"  {'í´ë˜ìŠ¤':<22} | {'ë§ì¶¤':>5} | {'ì „ì²´':>5} | {'ì •í™•ë„':>8} | {'ì£¼ìš” ì˜¤ë¶„ë¥˜'}")
        for cn in CLASS_NAMES:
            s = ds["class_stats"][cn]
            a = s["correct"] / s["total"] * 100 if s["total"] else 0
            ws = ""
            if s["wrong_preds"]:
                wc = {}
                for _, wp, _, *_ in s["wrong_preds"]:
                    wc[wp] = wc.get(wp, 0) + 1
                ws = ", ".join(f"{k}({v})" for k, v in sorted(wc.items(), key=lambda x: -x[1])[:2])
            bar = "â–ˆ" * int(a // 10) + "â–‘" * (10 - int(a // 10))
            print(f"  {cn:<22} | {s['correct']:>5} | {s['total']:>5} | {a:>5.1f}% {bar} | {ws}")

    # 3) ì „ì²´ í´ë˜ìŠ¤ë³„ í†µí•© ì •í™•ë„
    print(f"\n{'='*100}")
    print("ğŸ“Š [ì „ì²´ í†µí•© â€” í´ë˜ìŠ¤ë³„ ì •í™•ë„]")
    print("=" * 100)
    print(f"{'í´ë˜ìŠ¤':<22} | {'ë§ì¶¤':>6} | {'ì „ì²´':>6} | {'ì •í™•ë„':>10} | {'ì£¼ìš” ì˜¤ë¶„ë¥˜'}")
    print("-" * 100)

    for cn in CLASS_NAMES:
        s = class_stats[cn]
        acc = s["correct"] / s["total"] * 100 if s["total"] else 0
        ws = ""
        if s["wrong_preds"]:
            wc = {}
            for _, wp, _, *_ in s["wrong_preds"]:
                wc[wp] = wc.get(wp, 0) + 1
            ws = ", ".join(f"{k}({v})" for k, v in sorted(wc.items(), key=lambda x: -x[1])[:3])
        bar = "â–ˆ" * int(acc // 10) + "â–‘" * (10 - int(acc // 10))
        print(f"{cn:<22} | {s['correct']:>6} | {s['total']:>6} | {acc:>6.1f}% {bar} | {ws}")

    print("=" * 100)
    print(f"ğŸ¯ ìµœì¢… í†µí•© ì •í™•ë„: {total_acc:.2f}% ({total_correct}/{total_count})")
    print(f"   ëª¨ë¸: {os.path.basename(MODEL_PATH)}")
    if SAVE_REPORTS:
        print(f"   ğŸ“‚ ë¦¬í¬íŠ¸: {RESULT_DIR}")
    print("=" * 100)


if __name__ == "__main__":
    run_all_tests()
