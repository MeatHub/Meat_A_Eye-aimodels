import os
import json
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, WeightedRandomSampler
from torchvision import datasets, models
from pathlib import Path
import albumentations as A
from albumentations.pytorch import ToTensorV2
import numpy as np
import random
from collections import Counter
from datasets import load_dataset
from dotenv import load_dotenv

load_dotenv()

# ===== ì„¤ì • =====
DATA_ROOT = Path(__file__).parent.parent / "data" / "dataset_final"
CONFIG = {
    # â”€â”€ ë°ì´í„° ê²½ë¡œ (train/val/test í´ë”ê°€ ì´ë¯¸ ë¶„ë¦¬ë˜ì–´ ìˆìŒ) â”€â”€
    "train_dir": DATA_ROOT / "train",
    "val_dir":   DATA_ROOT / "val",
    "test_dir":  DATA_ROOT / "test",
    # â”€â”€ ëª¨ë¸ ì €ì¥ â”€â”€
    "model_save_path": Path(__file__).parent / "models" / "b2_imagenet_beef.pth",
    "checkpoint_dir":  Path(__file__).parent / "models" / "checkpoints",
    # â”€â”€ í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° â”€â”€
    "num_epochs": 30,
    "batch_size": 32,
    "learning_rate": 1e-4,         # Backbone (features) í•™ìŠµë¥ 
    "head_learning_rate": 1e-3,    # Classifier (head) í•™ìŠµë¥ 
    "image_size": 260,
    "num_workers": 8,
    "mixup_alpha": 0.2,
    "label_smoothing": 0.1,
    "weight_decay": 1e-2,
    "grad_clip_max_norm": 1.0,     # Gradient clipping
    # â”€â”€ Early Stopping â”€â”€
    "patience": 10,                # val_acc ê°œì„  ì—†ìœ¼ë©´ N epoch í›„ ì¤‘ë‹¨
    # â”€â”€ LR Warmup â”€â”€
    "warmup_epochs": 3,            # ì„ í˜• warmup ì—í­ ìˆ˜
    # â”€â”€ TTA (Test Time Augmentation) â”€â”€
    "tta_transforms": 5,           # í…ŒìŠ¤íŠ¸ ì‹œ ì¦ê°• íšŸìˆ˜ (1 = ì¦ê°• ì—†ìŒ)
    # â”€â”€ Class Weighting â”€â”€
    "use_weighted_sampler": True,  # í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì •
    # â”€â”€ ImageNet ì‚¬ì „í•™ìŠµ (ì„ íƒ) â”€â”€
    "imagenet_dataset_id": "ILSVRC/imagenet-1k",
    "imagenet_pretrain_epochs": 0,
    "imagenet_batch_size": 64,
    "imagenet_max_samples": 100_000,
    "imagenet_model_path": Path(__file__).parent / "models" / "efficientnet_b2_imagenet.pth",
    "hf_token": None,
}

# ===== [í•µì‹¬ 1] ì¦ê°• ì „ëµ â€” ì†Œê³ ê¸° ë¶€ìœ„ ì§ˆê°Â·ìƒ‰ìƒÂ·ë§ˆë¸”ë§ íŠ¹í™” =====
train_transform = A.Compose([
    A.Resize(CONFIG["image_size"], CONFIG["image_size"]),
    A.Affine(translate_percent=0.1, scale=(0.8, 1.2), rotate=(-30, 30), p=0.5),
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.3),
    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),
    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),
    A.CLAHE(clip_limit=2.0, p=0.3),
    A.GaussNoise(p=0.2),
    A.GaussianBlur(blur_limit=(3, 5), p=0.2),
    A.CoarseDropout(
        num_holes_range=(1, 8),
        hole_height_range=(0.02, 0.1),
        hole_width_range=(0.02, 0.1),
        p=0.5,
    ),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

val_transform = A.Compose([
    A.Resize(CONFIG["image_size"], CONFIG["image_size"]),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

# TTAìš© ê²½ëŸ‰ ì¦ê°• (í…ŒìŠ¤íŠ¸ ì‹œ ì—¬ëŸ¬ ë²ˆ ì ìš© í›„ í‰ê· )
tta_transform = A.Compose([
    A.Resize(CONFIG["image_size"], CONFIG["image_size"]),
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])


# ===== [í•µì‹¬ 2] Mixup =====
def mixup_data(x, y, alpha=1.0):
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1
    batch_size = x.size()[0]
    index = torch.randperm(batch_size, device=x.device)
    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam


def mixup_criterion(criterion, pred, y_a, y_b, lam):
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)


# ===== Dataset ë˜í¼ =====
class AlbumentationsDataset(torch.utils.data.Dataset):
    """ImageFolder ê²°ê³¼ë¥¼ Albumentations ì¦ê°•ê³¼ ì—°ê²°."""
    def __init__(self, dataset, transform=None):
        self.dataset = dataset
        self.transform = transform

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        image, label = self.dataset[idx]
        image = np.array(image)
        if self.transform:
            image = self.transform(image=image)["image"]
        return image, label


class ImageNetAlbumentationsDataset(torch.utils.data.Dataset):
    """HuggingFace ImageNet â†’ Albumentations í˜¸í™˜ ë˜í¼."""
    def __init__(self, hf_dataset, transform=None):
        self.hf_dataset = hf_dataset
        self.transform = transform

    def __len__(self):
        return len(self.hf_dataset)

    def __getitem__(self, idx):
        row = self.hf_dataset[idx]
        image = np.array(row["image"].convert("RGB"))
        label = row["label"]
        if self.transform:
            image = self.transform(image=image)["image"]
        return image, label


# ===== ëª¨ë¸ ìƒì„± =====
def create_model_b2(num_classes: int, pretrained_path=None):
    model = models.efficientnet_b2(weights=models.EfficientNet_B2_Weights.DEFAULT)
    model.classifier = nn.Sequential(
        nn.Dropout(p=0.4, inplace=True),
        nn.Linear(model.classifier[1].in_features, num_classes),
    )
    if pretrained_path and Path(pretrained_path).exists():
        state = torch.load(pretrained_path, map_location="cpu", weights_only=True)
        state = {k: v for k, v in state.items() if not k.startswith("classifier")}
        model.load_state_dict(state, strict=False)
        print(f"  âœ“ Backbone ë¡œë“œ: {pretrained_path}")
    return model


def create_model_imagenet():
    return models.efficientnet_b2(weights=models.EfficientNet_B2_Weights.DEFAULT)


# ===== WeightedRandomSampler ìƒì„± =====
def make_weighted_sampler(dataset: datasets.ImageFolder) -> WeightedRandomSampler:
    """í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì •ì„ ìœ„í•œ ê°€ì¤‘ ìƒ˜í”ŒëŸ¬ ìƒì„±."""
    targets = dataset.targets
    class_counts = Counter(targets)
    num_samples = len(targets)
    class_weights = {cls: num_samples / count for cls, count in class_counts.items()}
    sample_weights = [class_weights[t] for t in targets]
    return WeightedRandomSampler(
        weights=sample_weights,
        num_samples=num_samples,
        replacement=True,
    )


# ===== Early Stopping =====
class EarlyStopping:
    def __init__(self, patience: int = 10, min_delta: float = 1e-4):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_score = None

    def __call__(self, val_acc: float) -> bool:
        if self.best_score is None or val_acc > self.best_score + self.min_delta:
            self.best_score = val_acc
            self.counter = 0
            return False  # ê³„ì† í•™ìŠµ
        self.counter += 1
        if self.counter >= self.patience:
            print(f"  â¹ Early Stopping ë°œë™ (patience={self.patience}, best={self.best_score:.4f})")
            return True  # í•™ìŠµ ì¤‘ë‹¨
        return False


# ===== LR Warmup + CosineAnnealing ìŠ¤ì¼€ì¤„ëŸ¬ =====
class WarmupCosineScheduler:
    """Linear warmup â†’ CosineAnnealingWarmRestarts."""
    def __init__(self, optimizer, warmup_epochs, total_epochs, warmup_start_lr=1e-6):
        self.optimizer = optimizer
        self.warmup_epochs = warmup_epochs
        self.warmup_start_lr = warmup_start_lr
        self.base_lrs = [pg["lr"] for pg in optimizer.param_groups]
        self.cosine = optim.lr_scheduler.CosineAnnealingWarmRestarts(
            optimizer, T_0=max(total_epochs - warmup_epochs, 1), T_mult=1
        )
        self.current_epoch = 0

    def step(self):
        self.current_epoch += 1
        if self.current_epoch <= self.warmup_epochs:
            # Linear warmup
            alpha = self.current_epoch / self.warmup_epochs
            for pg, base_lr in zip(self.optimizer.param_groups, self.base_lrs):
                pg["lr"] = self.warmup_start_lr + alpha * (base_lr - self.warmup_start_lr)
        else:
            self.cosine.step()

    def get_last_lr(self):
        return [pg["lr"] for pg in self.optimizer.param_groups]


# ===== í‰ê°€ í•¨ìˆ˜ =====
def evaluate(model, loader, device, class_names):
    """Validation/Test ì„¸íŠ¸ í‰ê°€ â€” accuracy + per-class precision/recall/F1."""
    model.eval()
    num_classes = len(class_names)
    confusion = torch.zeros(num_classes, num_classes, dtype=torch.long)  # [pred, true]

    with torch.no_grad():
        for inputs, labels in loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            preds = outputs.argmax(dim=1)
            for p, t in zip(preds.cpu(), labels.cpu()):
                confusion[p, t] += 1

    # Overall accuracy
    total = confusion.sum().item()
    correct = confusion.diag().sum().item()
    accuracy = correct / total if total > 0 else 0.0

    # Per-class metrics
    per_class = {}
    for i, name in enumerate(class_names):
        tp = confusion[i, i].item()
        fp = confusion[i, :].sum().item() - tp
        fn = confusion[:, i].sum().item() - tp
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
        per_class[name] = {"precision": precision, "recall": recall, "f1": f1}

    return accuracy, per_class, confusion


def evaluate_with_tta(model, dataset_raw, device, class_names, num_augments=5):
    """Test Time Augmentation â€” ì—¬ëŸ¬ ë²ˆ ì¦ê°• í›„ ì†Œí”„íŠ¸ë§¥ìŠ¤ í‰ê· ìœ¼ë¡œ ì˜ˆì¸¡."""
    model.eval()
    num_classes = len(class_names)
    confusion = torch.zeros(num_classes, num_classes, dtype=torch.long)

    for idx in range(len(dataset_raw)):
        image, label = dataset_raw[idx]
        img_np = np.array(image)

        # ì›ë³¸ (val_transform) + N-1 ë²ˆ tta_transform
        logits_sum = None
        for i in range(num_augments):
            tf = val_transform if i == 0 else tta_transform
            aug = tf(image=img_np)["image"].unsqueeze(0).to(device)
            with torch.no_grad():
                out = model(aug)
                probs = torch.softmax(out, dim=1)
            logits_sum = probs if logits_sum is None else logits_sum + probs

        pred = logits_sum.argmax(dim=1).item()
        confusion[pred, label] += 1

    total = confusion.sum().item()
    correct = confusion.diag().sum().item()
    accuracy = correct / total if total > 0 else 0.0

    per_class = {}
    for i, name in enumerate(class_names):
        tp = confusion[i, i].item()
        fp = confusion[i, :].sum().item() - tp
        fn = confusion[:, i].sum().item() - tp
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
        per_class[name] = {"precision": precision, "recall": recall, "f1": f1}

    return accuracy, per_class, confusion


def print_metrics(accuracy, per_class, class_names, title="Evaluation"):
    """í‰ê°€ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥."""
    print(f"\n{'='*60}")
    print(f"  {title}")
    print(f"{'='*60}")
    print(f"  Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"{'â”€'*60}")
    print(f"  {'Class':<22} {'Prec':>7} {'Recall':>7} {'F1':>7}")
    print(f"  {'â”€'*22} {'â”€'*7} {'â”€'*7} {'â”€'*7}")
    macro_p, macro_r, macro_f1 = 0, 0, 0
    for name in class_names:
        m = per_class[name]
        print(f"  {name:<22} {m['precision']:>7.4f} {m['recall']:>7.4f} {m['f1']:>7.4f}")
        macro_p += m["precision"]
        macro_r += m["recall"]
        macro_f1 += m["f1"]
    n = len(class_names)
    print(f"  {'â”€'*22} {'â”€'*7} {'â”€'*7} {'â”€'*7}")
    print(f"  {'Macro Avg':<22} {macro_p/n:>7.4f} {macro_r/n:>7.4f} {macro_f1/n:>7.4f}")
    print(f"{'='*60}\n")


# ===== ëª¨ë¸ ì €ì¥ (ë©”íƒ€ë°ì´í„° í¬í•¨) =====
def save_checkpoint(model, class_to_idx, epoch, val_acc, path):
    """ëª¨ë¸ ê°€ì¤‘ì¹˜ + ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ì €ì¥."""
    path = Path(path)
    path.parent.mkdir(parents=True, exist_ok=True)

    # state_dictë§Œ ì €ì¥ (predict_b2.py í˜¸í™˜)
    torch.save(model.state_dict(), path)

    # ë©”íƒ€ë°ì´í„°ë¥¼ ë³„ë„ JSONì— ì €ì¥
    meta = {
        "epoch": epoch,
        "val_acc": val_acc,
        "num_classes": len(class_to_idx),
        "class_to_idx": class_to_idx,
        "idx_to_class": {v: k for k, v in class_to_idx.items()},
        "image_size": CONFIG["image_size"],
    }
    meta_path = path.with_suffix(".json")
    with open(meta_path, "w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)
    print(f"  ğŸ’¾ ëª¨ë¸ ì €ì¥: {path.name}  |  ë©”íƒ€: {meta_path.name}")


# ===== ë©”ì¸ =====
def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Device: {device}")
    if device.type == "cuda":
        print(f"  GPU: {torch.cuda.get_device_name(0)}")
    pretrained_path = None

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # [Phase 1] ImageNet ì‚¬ì „í•™ìŠµ (ì„ íƒ, epochs=0ì´ë©´ ìŠ¤í‚µ)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if CONFIG["imagenet_pretrain_epochs"] > 0:
        print("\n[Phase 1] ImageNet ì‚¬ì „í•™ìŠµ ì‹œì‘")
        hf_token = CONFIG.get("hf_token") or os.environ.get("HF_TOKEN")
        if not hf_token:
            print("  âš  ImageNet(gated) ì ‘ê·¼ì„ ìœ„í•´ HF í† í°ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            print("  CONFIG['hf_token'] ë˜ëŠ” .env HF_TOKEN ì„¤ì • í›„ ì¬ì‹¤í–‰.")
            raise RuntimeError("HF_TOKEN not set.")
        try:
            imagenet_dataset = load_dataset(
                CONFIG["imagenet_dataset_id"], split="train", token=hf_token,
            )
        except Exception as e:
            if "gated" in str(e).lower() or "DatasetNotFoundError" in type(e).__name__:
                print("  âš  ImageNetì€ gated ë°ì´í„°ì…‹ì…ë‹ˆë‹¤. HF ì´ìš©ì•½ê´€ ë™ì˜ í•„ìš”.")
            raise
        if CONFIG["imagenet_max_samples"] is not None:
            n = min(len(imagenet_dataset), CONFIG["imagenet_max_samples"])
            imagenet_dataset = imagenet_dataset.select(range(n))
            print(f"  ImageNet ì„œë¸Œì…‹: {n:,} ìƒ˜í”Œ")
        ds = ImageNetAlbumentationsDataset(imagenet_dataset, val_transform)
        il = DataLoader(ds, batch_size=CONFIG["imagenet_batch_size"],
                        shuffle=True, num_workers=CONFIG["num_workers"], pin_memory=True)
        model_imagenet = create_model_imagenet().to(device)
        opt = optim.AdamW(model_imagenet.parameters(), lr=1e-4, weight_decay=1e-2)
        crit = nn.CrossEntropyLoss()
        for ep in range(CONFIG["imagenet_pretrain_epochs"]):
            model_imagenet.train()
            running, correct, total = 0.0, 0, 0
            for x, y in il:
                x, y = x.to(device), y.to(device)
                opt.zero_grad()
                out = model_imagenet(x)
                loss = crit(out, y)
                loss.backward()
                opt.step()
                running += loss.item()
                correct += (out.argmax(1) == y).sum().item()
                total += y.size(0)
            print(f"  ImageNet Epoch [{ep+1}/{CONFIG['imagenet_pretrain_epochs']}] "
                  f"Loss: {running/len(il):.4f}  Acc: {correct/total:.4f}")
        CONFIG["imagenet_model_path"].parent.mkdir(parents=True, exist_ok=True)
        torch.save(model_imagenet.state_dict(), CONFIG["imagenet_model_path"])
        pretrained_path = CONFIG["imagenet_model_path"]
        del model_imagenet, il, ds, imagenet_dataset
        if device.type == "cuda":
            torch.cuda.empty_cache()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # [Phase 2] ì†Œê³ ê¸° ë¶€ìœ„ ë¶„ë¥˜ Fine-tuning
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n[Phase 2] ì†Œê³ ê¸° ë¶€ìœ„ ë¶„ë¥˜ Fine-tuning")

    # ë°ì´í„° ë¡œë“œ (ì‹¤ì œ train / val / test ë””ë ‰í† ë¦¬ ì‚¬ìš©)
    for split, d in [("train", CONFIG["train_dir"]), ("val", CONFIG["val_dir"]), ("test", CONFIG["test_dir"])]:
        if not Path(d).exists():
            raise FileNotFoundError(f"{split} ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤: {d}")

    train_dataset = datasets.ImageFolder(root=str(CONFIG["train_dir"]))
    val_dataset   = datasets.ImageFolder(root=str(CONFIG["val_dir"]))
    test_dataset  = datasets.ImageFolder(root=str(CONFIG["test_dir"]))

    class_names = train_dataset.classes
    class_to_idx = train_dataset.class_to_idx
    num_classes = len(class_names)

    # í´ë˜ìŠ¤ ë¶„í¬ ì¶œë ¥
    train_counts = Counter(train_dataset.targets)
    print(f"  í´ë˜ìŠ¤ ìˆ˜: {num_classes}")
    print(f"  Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}")
    print(f"  í´ë˜ìŠ¤ ë¶„í¬ (train):")
    for idx in sorted(train_counts.keys()):
        name = class_names[idx]
        count = train_counts[idx]
        bar = "â–ˆ" * (count // 10)
        print(f"    {name:<22} {count:>4}  {bar}")

    # DataLoader êµ¬ì„±
    if CONFIG["use_weighted_sampler"]:
        sampler = make_weighted_sampler(train_dataset)
        train_loader = DataLoader(
            AlbumentationsDataset(train_dataset, train_transform),
            batch_size=CONFIG["batch_size"],
            sampler=sampler,
            num_workers=CONFIG["num_workers"],
            pin_memory=True,
        )
        print("  âœ“ WeightedRandomSampler ì ìš© (í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì •)")
    else:
        train_loader = DataLoader(
            AlbumentationsDataset(train_dataset, train_transform),
            batch_size=CONFIG["batch_size"],
            shuffle=True,
            num_workers=CONFIG["num_workers"],
            pin_memory=True,
        )

    val_loader = DataLoader(
        AlbumentationsDataset(val_dataset, val_transform),
        batch_size=CONFIG["batch_size"],
        shuffle=False,
        num_workers=CONFIG["num_workers"],
        pin_memory=True,
    )

    # ëª¨ë¸
    model = create_model_b2(num_classes, pretrained_path=pretrained_path).to(device)

    # ì°¨ë“± í•™ìŠµë¥ : Backbone ëŠë¦¬ê²Œ, Head ë¹ ë¥´ê²Œ
    optimizer = optim.AdamW([
        {"params": model.features.parameters(), "lr": CONFIG["learning_rate"]},
        {"params": model.classifier.parameters(), "lr": CONFIG["head_learning_rate"]},
    ], weight_decay=CONFIG["weight_decay"])

    criterion = nn.CrossEntropyLoss(label_smoothing=CONFIG["label_smoothing"])
    scheduler = WarmupCosineScheduler(optimizer, CONFIG["warmup_epochs"], CONFIG["num_epochs"])
    early_stopping = EarlyStopping(patience=CONFIG["patience"])

    best_val_acc = 0.0
    CONFIG["checkpoint_dir"].mkdir(parents=True, exist_ok=True)

    print(f"\n  í•™ìŠµ ì‹œì‘: {CONFIG['num_epochs']} epochs, batch={CONFIG['batch_size']}, "
          f"warmup={CONFIG['warmup_epochs']}, patience={CONFIG['patience']}")
    print(f"  LR backbone={CONFIG['learning_rate']}, head={CONFIG['head_learning_rate']}")
    print(f"{'â”€'*70}")

    for epoch in range(CONFIG["num_epochs"]):
        epoch_start = time.time()

        # === Training ===
        model.train()
        train_loss, train_correct, train_total = 0.0, 0.0, 0
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            # Mixup
            inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, CONFIG["mixup_alpha"])

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)
            loss.backward()

            # Gradient clipping
            nn.utils.clip_grad_norm_(model.parameters(), CONFIG["grad_clip_max_norm"])

            optimizer.step()

            train_loss += loss.item() * inputs.size(0)
            train_correct += (lam * (outputs.argmax(1) == labels_a).float().sum()
                              + (1 - lam) * (outputs.argmax(1) == labels_b).float().sum()).item()
            train_total += inputs.size(0)

        # === Validation ===
        val_acc, val_per_class, _ = evaluate(model, val_loader, device, class_names)

        scheduler.step()
        elapsed = time.time() - epoch_start
        t_loss = train_loss / train_total
        t_acc  = train_correct / train_total
        lrs = scheduler.get_last_lr()

        print(f"  Epoch [{epoch+1:>3}/{CONFIG['num_epochs']}]  "
              f"Train Loss: {t_loss:.4f}  Train Acc: {t_acc:.4f}  |  "
              f"Val Acc: {val_acc:.4f}  |  "
              f"LR: {lrs[0]:.2e}/{lrs[1]:.2e}  |  {elapsed:.1f}s")

        # Best ëª¨ë¸ ì €ì¥
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            save_checkpoint(model, class_to_idx, epoch + 1, val_acc, CONFIG["model_save_path"])
            print(f"  â­ Best Model Updated! (Val Acc: {val_acc:.4f})")

        # ì£¼ê¸°ì  ì²´í¬í¬ì¸íŠ¸ (10 ì—í­ë§ˆë‹¤)
        if (epoch + 1) % 10 == 0:
            ckpt_path = CONFIG["checkpoint_dir"] / f"epoch_{epoch+1:03d}.pth"
            save_checkpoint(model, class_to_idx, epoch + 1, val_acc, ckpt_path)

        # Early Stopping í™•ì¸
        if early_stopping(val_acc):
            print(f"  â†’ {epoch+1} epochì—ì„œ í•™ìŠµ ì¢…ë£Œ (Early Stopping)")
            break

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # [Phase 3] Test ì„¸íŠ¸ ìµœì¢… í‰ê°€
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n[Phase 3] Test ì„¸íŠ¸ ìµœì¢… í‰ê°€")

    # Best ëª¨ë¸ ë‹¤ì‹œ ë¡œë“œ
    best_state = torch.load(CONFIG["model_save_path"], map_location=device, weights_only=True)
    model.load_state_dict(best_state)
    model.eval()

    # ì¼ë°˜ í‰ê°€
    test_loader = DataLoader(
        AlbumentationsDataset(test_dataset, val_transform),
        batch_size=CONFIG["batch_size"],
        shuffle=False,
        num_workers=CONFIG["num_workers"],
        pin_memory=True,
    )
    test_acc, test_per_class, test_confusion = evaluate(model, test_loader, device, class_names)
    print_metrics(test_acc, test_per_class, class_names, title="Test Set â€” ì¼ë°˜ í‰ê°€")

    # TTA í‰ê°€
    if CONFIG["tta_transforms"] > 1:
        print(f"  TTA í‰ê°€ ì¤‘ (augments={CONFIG['tta_transforms']})...")
        tta_acc, tta_per_class, tta_confusion = evaluate_with_tta(
            model, test_dataset, device, class_names, CONFIG["tta_transforms"]
        )
        print_metrics(tta_acc, tta_per_class, class_names, title=f"Test Set â€” TTA (x{CONFIG['tta_transforms']})")

    # Confusion Matrix ì¶œë ¥
    print("  Confusion Matrix (rows=predicted, cols=actual):")
    header = "          " + " ".join(f"{n[:6]:>6}" for n in class_names)
    print(header)
    for i, name in enumerate(class_names):
        row = " ".join(f"{test_confusion[i, j].item():>6}" for j in range(num_classes))
        print(f"  {name[:8]:>8}  {row}")

    print(f"\nâœ… í•™ìŠµ ì™„ë£Œ! Best Val Acc: {best_val_acc:.4f} | Test Acc: {test_acc:.4f}")
    print(f"   ëª¨ë¸: {CONFIG['model_save_path']}")
    print(f"   ë©”íƒ€: {CONFIG['model_save_path'].with_suffix('.json')}")


if __name__ == "__main__":
    main()