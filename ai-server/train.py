import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, models
from pathlib import Path
import albumentations as A
from albumentations.pytorch import ToTensorV2
import numpy as np
import random

# 1. ì¥ë¹„ ì„¤ì • (ë§¥ë¶ MPS ìš°ì„ , ì—†ìœ¼ë©´ CPU)
DEVICE = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
if torch.cuda.is_available():
    DEVICE = torch.device("cuda")

print(f"ğŸš€ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì¥ë¹„: {DEVICE}")

# ===== ì„¤ì • (ë§¥ë¶ ì—ì–´ ìµœì í™” + íŒŒì¸íŠœë‹) =====
# [í•™ìŠµ ì‹œë‚˜ë¦¬ì˜¤]
# - MODE = "all"         : ì†Œ+ë¼ì§€ ì „ì²´ í•™ìŠµ (ê¸°ë³¸ê°’)
# - MODE = "pork_focus"  : ë¼ì§€ ë“±ì‹¬/ì•ˆì‹¬ì— ê°€ì¤‘ì¹˜ ì‹¤ì–´ì„œ ì§‘ì¤‘ í•™ìŠµ, ë³„ë„ pthë¡œ ì €ì¥
# - fine_tune=False      : ImageNet â†’ í•œ ë²ˆì— í•™ìŠµ (ê¶Œì¥)
# - fine_tune=True       : ê¸°ì¡´ pth ì´ì–´ì„œ í•™ìŠµ (í´ë˜ìŠ¤ ìˆ˜ ë™ì¼í•  ë•Œë§Œ)
CONFIG = {
    "mode": "all",  # "all" ë˜ëŠ” "pork_focus"
    "dataset_root": Path(__file__).resolve().parent.parent / "data" / "dataset_final",
    "model_save_path": Path(__file__).resolve().parent / "models" / "meat_vision_b2_pro.pth",
    "pretrained_model_path": Path(__file__).resolve().parent / "models" / "meat_vision_b2_pro.pth",  # íŒŒì¸íŠœë‹ìš© ê¸°ì¡´ ëª¨ë¸ ê²½ë¡œ
    "num_epochs": 30,             # ì „ì²´ í•™ìŠµ ê¶Œì¥ 15~30 / íŒŒì¸íŠœë‹ ì‹œ 3~5
    "batch_size": 16,             # ë§¥ë¶ ì—ì–´ ê¶Œì¥ (ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ 8ë¡œ ì¤„ì´ì„¸ìš”)
    "learning_rate": 5e-6,        # Backbone (ImageNet íŒŒì¸íŠœë‹)
    "head_learning_rate": 5e-4,   # Classifier
    "train_ratio": 0.8,
    "image_size": 260,
    "num_workers": 0,             # [ì¤‘ìš”] ë§¥ë¶ ì—ì–´ 8GBì—ì„œëŠ” 0ì´ ê°€ì¥ ì•ˆì „í•©ë‹ˆë‹¤.
    "mixup_alpha": 0.2,
    "fine_tune": False,           # ì†Œ+ë¼ì§€ í†µí•© ì²« í•™ìŠµ: False / ê¸°ì¡´ ëª¨ë¸ ì´ì–´ë°›ê¸°: True (í´ë˜ìŠ¤ ìˆ˜ ë™ì¼ ì‹œ)
    # ê¸°ë³¸ ê°€ì¤‘ì¹˜ (ì†Œ ë“±ì‹¬Â·ì•ˆì‹¬)
    "class_weight_ribeye_tenderloin": 1.3,  # ë“±ì‹¬Â·ì•ˆì‹¬ Loss ê°€ì¤‘ì¹˜ (1.0 = ë¯¸ì ìš©, 1.2~1.5 ê¶Œì¥)
    # ëª¨ë“œë³„ë¡œ ë®ì–´ì“¸ ìˆ˜ ìˆëŠ” í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ë”•ì…”ë„ˆë¦¬
    # ì˜ˆì‹œ) "pork_focus"ì—ì„œ Pork_Loin / Pork_Tenderloinë§Œ 1.5ë¡œ ì£¼ê¸° ë“±
    "class_weights": {
        "Pork_Loin": 1.7,
        "Pork_Tenderloin": 1.7,
    },
}

# ===== ëª¨ë“œë³„ ì„¤ì • ë®ì–´ì“°ê¸° =====
MODE = CONFIG.get("mode", "all")

if MODE == "pork_focus":
    # ë¼ì§€ ë“±ì‹¬/ì•ˆì‹¬ ì§‘ì¤‘ í•™ìŠµ ëª¨ë“œ
    # - ì €ì¥ íŒŒì¼ëª… ë”°ë¡œ ê´€ë¦¬
    CONFIG["model_save_path"] = Path(__file__).resolve().parent / "models" / "meat_vision_b2_pork_focus.pth"
    # - ë¼ì§€ ë“±ì‹¬/ì•ˆì‹¬ì— ê°€ì¤‘ì¹˜ ëª°ì•„ì£¼ê¸°
    CONFIG["class_weights"] = {
        "Pork_Loin": 1.5,
        "Pork_Tenderloin": 1.5,
    }

# ë””ë ‰í† ë¦¬ ìë™ ìƒì„± (mode ë°˜ì˜ëœ ê²½ë¡œ ê¸°ì¤€)
os.makedirs(Path(CONFIG["model_save_path"]).parent, exist_ok=True)

# ===== [í•µì‹¬ 1] ì¦ê°• ì „ëµ =====
# ğŸ‘‰ ê¸°ì¡´ë³´ë‹¤ â€œì•½í•˜ê²Œâ€: ë¸”ëŸ¬/ë…¸ì´ì¦ˆ/CoarseDropout ì œê±°, ê¸°í•˜/ìƒ‰ìƒ ë³€í˜•ë„ ë²”ìœ„Â·í™•ë¥  ì¶•ì†Œ
train_transform = A.Compose([
    A.Resize(CONFIG["image_size"], CONFIG["image_size"]),
    # ìœ„ì¹˜/í¬ê¸°/ê°ë„: ì‚´ì§ë§Œ ë³€í˜•
    A.Affine(
        translate_percent=0.10,
        scale=(0.85, 1.15),
        rotate=(-20, 20),
        p=0.5,
    ),
    A.HorizontalFlip(p=0.5),
    # ìƒ‰ê°: ê³¼í•˜ì§€ ì•Šê²Œ ì¡°ì •
    A.ColorJitter(
        brightness=0.25,
        contrast=0.25,
        saturation=0.25,
        hue=0.05,
        p=0.6,
    ),
    # ì‚´ì§ë§Œ íë¦¬ê²Œ (ê³¼í•œ ë¸”ëŸ¬ ë°©ì§€)
    A.GaussianBlur(blur_limit=(3, 5), p=0.2),
    A.RandomBrightnessContrast(
        brightness_limit=0.2,
        contrast_limit=0.2,
        p=0.4,
    ),
    A.HueSaturationValue(
        hue_shift_limit=8,
        sat_shift_limit=15,
        val_shift_limit=8,
        p=0.4,
    ),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

val_transform = A.Compose([
    A.Resize(CONFIG["image_size"], CONFIG["image_size"]),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

# ===== [í•µì‹¬ 2] Mixup ë° ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (ìˆ˜ì • ì™„ë£Œ) =====

# 1. Mixup ë°ì´í„° ìƒì„± í•¨ìˆ˜ (ì¥ë¹„ ì¶©ëŒ í•´ê²°ë¨)
def mixup_data(x, y, alpha=1.0):
    '''Returns mixed inputs, pairs of targets, and lambda'''
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1

    batch_size = x.size()[0]
    
    # [ìˆ˜ì •] ê³„ì‚° ì „ì— ë°ì´í„°ë¥¼ DEVICEë¡œ ë¨¼ì € ë³´ëƒ…ë‹ˆë‹¤.
    x = x.to(DEVICE)
    y = y.to(DEVICE)
    
    index = torch.randperm(batch_size).to(DEVICE)

    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam

# 2. Mixup ì†ì‹¤ í•¨ìˆ˜ (ëˆ„ë½ ë³µêµ¬ë¨)
def mixup_criterion(criterion, pred, y_a, y_b, lam):
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)

# 3. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (ëˆ„ë½ ë³µêµ¬ë¨)
class AlbumentationsDataset(torch.utils.data.Dataset):
    def __init__(self, dataset, transform=None):
        self.dataset = dataset
        self.transform = transform

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        image, label = self.dataset[idx]
        image = np.array(image)
        
        if self.transform:
            augmented = self.transform(image=image)
            image = augmented["image"]
            
        return image, label

# ===== [í•µì‹¬ 3] ëª¨ë¸ ìƒì„± =====
def create_model_b2(num_classes: int):
    model = models.efficientnet_b2(weights=models.EfficientNet_B2_Weights.DEFAULT)
    model.classifier = nn.Sequential(
        nn.Dropout(p=0.4, inplace=True),
        nn.Linear(model.classifier[1].in_features, num_classes)
    )
    return model

# ===== ë©”ì¸ í•¨ìˆ˜ =====
def main():
    # ë°ì´í„°ì…‹ ë¡œë“œ
    print(f"ğŸ“ ë°ì´í„° ì½ëŠ” ì¤‘... ê²½ë¡œ: {CONFIG['dataset_root']}")
    
    # í´ë”ê°€ ì‹¤ì œë¡œ ìˆëŠ”ì§€ ì²´í¬
    if not CONFIG["dataset_root"].exists():
        print(f"âŒ ì—ëŸ¬: ë°ì´í„° í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤! ({CONFIG['dataset_root']})")
        return

    train_dataset = datasets.ImageFolder(root=CONFIG["dataset_root"] / "train")
    val_dataset = datasets.ImageFolder(root=CONFIG["dataset_root"] / "val")
    test_dataset = datasets.ImageFolder(root=CONFIG["dataset_root"] / "test")

    num_classes = len(train_dataset.classes)
    print(f"âœ… í´ë˜ìŠ¤ ê°œìˆ˜: {num_classes}ê°œ")

    # ===== Loss ê°€ì¤‘ì¹˜ ì„¤ì • =====
    # 1) class_weights ë”•ì…”ë„ˆë¦¬ê°€ ìˆìœ¼ë©´ ìš°ì„  ì ìš©
    class_weights_cfg = CONFIG.get("class_weights", {}) or {}
    if class_weights_cfg:
        class_weights = torch.ones(num_classes, dtype=torch.float32)
        for name, w in class_weights_cfg.items():
            if name in train_dataset.class_to_idx:
                idx = train_dataset.class_to_idx[name]
                class_weights[idx] = float(w)
        class_weights = class_weights.to(DEVICE)
        criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)
        print(f"   ğŸ“Œ í´ë˜ìŠ¤ë³„ Loss ê°€ì¤‘ì¹˜ ì ìš©:")
        for name, w in class_weights_cfg.items():
            if name in train_dataset.class_to_idx:
                print(f"      - {name}: {w}")
    else:
        # 2) ê¸°ì¡´ ë“±ì‹¬Â·ì•ˆì‹¬ í†µí•© ê°€ì¤‘ì¹˜ (ê³¼ê±° ì„¤ì •ê³¼ í˜¸í™˜ìš©)
        weight_val = CONFIG.get("class_weight_ribeye_tenderloin", 1.0)
        if weight_val != 1.0:
            class_weights = torch.ones(num_classes, dtype=torch.float32)
            for name in ("Beef_Ribeye", "Beef_Tenderloin"):
                if name in train_dataset.class_to_idx:
                    i = train_dataset.class_to_idx[name]
                    class_weights[i] = weight_val
            class_weights = class_weights.to(DEVICE)
            criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)
            print(f"   ğŸ“Œ ë“±ì‹¬Â·ì•ˆì‹¬ Loss ê°€ì¤‘ì¹˜: {weight_val}")
        else:
            criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

    # DataLoader ì„¤ì •
    train_loader = DataLoader(AlbumentationsDataset(train_dataset, train_transform), 
                              batch_size=CONFIG["batch_size"], shuffle=True, 
                              num_workers=CONFIG["num_workers"], pin_memory=False) # ë§¥ë¶ì€ pin_memory Falseê°€ ì† í¸í•¨
    
    val_loader = DataLoader(AlbumentationsDataset(val_dataset, val_transform), 
                            batch_size=CONFIG["batch_size"], shuffle=False, 
                            num_workers=CONFIG["num_workers"], pin_memory=False)

    test_loader = DataLoader(AlbumentationsDataset(test_dataset, val_transform),
                             batch_size=CONFIG["batch_size"], shuffle=False, 
                             num_workers=CONFIG["num_workers"], pin_memory=False)

    # ëª¨ë¸ ì¤€ë¹„
    model = create_model_b2(num_classes).to(DEVICE)
    
    # === íŒŒì¸íŠœë‹: ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ (D. í•™ìŠµ ì „ëµ) ===
    if CONFIG["fine_tune"] and os.path.exists(CONFIG["pretrained_model_path"]):
        print(f"\nğŸ“¥ ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì¤‘: {CONFIG['pretrained_model_path']}")
        try:
            model.load_state_dict(torch.load(CONFIG["pretrained_model_path"], map_location=DEVICE))
            print("âœ… ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! íŒŒì¸íŠœë‹ ëª¨ë“œë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("   ì²˜ìŒë¶€í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    else:
        if CONFIG["fine_tune"]:
            print("âš ï¸ ê¸°ì¡´ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        else:
            print("ğŸ†• ì²˜ìŒë¶€í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    # ì˜µí‹°ë§ˆì´ì € & ìŠ¤ì¼€ì¤„ëŸ¬
    optimizer = optim.AdamW([
        {'params': model.features.parameters(), 'lr': CONFIG["learning_rate"]},
        {'params': model.classifier.parameters(), 'lr': CONFIG["head_learning_rate"]}
    ], weight_decay=1e-2)

    # criterionì€ ìœ„ì—ì„œ class_weight ì ìš© ì—¬ë¶€ì— ë”°ë¼ ì´ë¯¸ ì •ì˜ë¨
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1)

    best_val_acc = 0.0
    
    mode_str = "íŒŒì¸íŠœë‹" if (CONFIG["fine_tune"] and os.path.exists(CONFIG["pretrained_model_path"])) else "ì²˜ìŒë¶€í„° í•™ìŠµ"
    print(f"\nğŸ”¥ MODE = {MODE} / {mode_str} ì‹œì‘! (MacBook Airê°€ ì¡°ê¸ˆ ëœ¨ê±°ì›Œì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    print(f"   - Backbone í•™ìŠµë¥ : {CONFIG['learning_rate']}")
    print(f"   - Classifier í•™ìŠµë¥ : {CONFIG['head_learning_rate']}")
    print(f"   - Epoch: {CONFIG['num_epochs']}\n")
    
    for epoch in range(CONFIG["num_epochs"]):
        # === Training Phase ===
        model.train()
        train_loss, train_correct = 0, 0
        
        # ì§„í–‰ ìƒí™© ê°„ë‹¨ í‘œì‹œ
        print(f"\n[Epoch {epoch+1}/{CONFIG['num_epochs']}] í•™ìŠµ ì§„í–‰ ì¤‘...", end=" ")
        
        for inputs, labels in train_loader:
            # inputs, labelsëŠ” mixup í•¨ìˆ˜ ì•ˆì—ì„œ to(DEVICE) ì²˜ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„  íŒ¨ìŠ¤í•´ë„ ë¨
            # í•˜ì§€ë§Œ ì•ˆì „í•˜ê²Œ í•œë²ˆ ë” í•´ë„ ë¬´ë°©í•¨
            
            # Mixup ì ìš© (ë‚´ë¶€ì—ì„œ DEVICEë¡œ ì´ë™)
            inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, CONFIG["mixup_alpha"])
            
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            
            # ì •í™•ë„ ê³„ì‚° (Mixup ê³ ë ¤)
            pred = outputs.argmax(1)
            train_correct += (lam * (pred == labels_a).float().sum() + 
                             (1 - lam) * (pred == labels_b).float().sum()).item()

        # === Validation Phase ===
        model.eval()
        val_correct = 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
                outputs = model(inputs)
                val_correct += (outputs.argmax(1) == labels).sum().item()

        scheduler.step()
        
        # ì •í™•ë„ ê³„ì‚°
        t_acc = train_correct / len(train_loader.dataset)
        v_acc = val_correct / len(val_loader.dataset)
        avg_train_loss = train_loss / len(train_loader)
        
        # ëª…í™•í•œ ì¶œë ¥ í˜•ì‹
        print(f"\n{'='*60}")
        print(f"Epoch [{epoch+1}/{CONFIG['num_epochs']}] ê²°ê³¼:")
        print(f"  ğŸ“Š Train Accuracy:  {t_acc:.4f} ({train_correct}/{len(train_loader.dataset)})")
        print(f"  ğŸ“Š Train Loss:       {avg_train_loss:.4f}")
        print(f"  ğŸ“Š Val Accuracy:    {v_acc:.4f} ({val_correct}/{len(val_loader.dataset)})")
        print(f"{'='*60}")

        if v_acc > best_val_acc:
            best_val_acc = v_acc
            torch.save(model.state_dict(), CONFIG["model_save_path"])
            print(f"  â­ ìµœê³  Validation Accuracy ê°±ì‹ ! ëª¨ë¸ ì €ì¥ë¨ ({v_acc:.4f})\n")

    # === ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê°€ ===
    if os.path.exists(CONFIG["model_save_path"]):
        print("\n=== ğŸ† ìµœì¢… í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€ ===")
        best_model = create_model_b2(num_classes).to(DEVICE)
        best_model.load_state_dict(torch.load(CONFIG["model_save_path"], map_location=DEVICE))
        best_model.eval()

        test_correct = 0
        with torch.no_grad():
            for inputs, labels in test_loader:
                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
                outputs = best_model(inputs)
                test_correct += (outputs.argmax(1) == labels).sum().item()

        test_acc = test_correct / len(test_loader.dataset)
        print(f"   ğŸ“Š ìµœì¢… Test Accuracy: {test_acc:.4f}")
    else:
        print("âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()