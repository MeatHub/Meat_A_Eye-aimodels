"""
ë°ì´í„°ì…‹ ê· í˜• ë¶„í•  ìŠ¤í¬ë¦½íŠ¸
- raw_datasetì—ì„œ ê° í´ë˜ìŠ¤ë‹¹ 100ì¥ì”© ê· ë“±í•˜ê²Œ ë¶„í• 
- train_dataset_1, train_dataset_2, ... í˜•ì‹ìœ¼ë¡œ ìˆœì°¨ ìƒì„±
- ì‚¬ìš©ëœ ì´ë¯¸ì§€ëŠ” ì›ë³¸ì—ì„œ ì‚­ì œ (ì´ë™)
"""

import os
import shutil
import random
import argparse
from pathlib import Path
from typing import Optional, List, Tuple


def get_all_images_from_raw(raw_dir: str, class_name: str) -> list:
    """raw_datasetì˜ train/test/val í´ë”ì—ì„œ í•´ë‹¹ í´ë˜ìŠ¤ì˜ ëª¨ë“  ì´ë¯¸ì§€ ìˆ˜ì§‘"""
    images = []
    raw_path = Path(raw_dir)
    
    # train/test/val êµ¬ì¡°ì¸ ê²½ìš°
    for split in ['train', 'test', 'val']:
        class_path = raw_path / split / class_name
        if class_path.exists():
            for img in class_path.iterdir():
                if img.is_file() and img.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.webp']:
                    images.append(img)
    
    # ì§ì ‘ í´ë˜ìŠ¤ í´ë”ê°€ ìˆëŠ” ê²½ìš°
    direct_class_path = raw_path / class_name
    if direct_class_path.exists() and direct_class_path.is_dir():
        for img in direct_class_path.iterdir():
            if img.is_file() and img.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.webp']:
                images.append(img)
    
    return images


def get_classes_from_raw(raw_dir: str) -> list:
    """raw_datasetì—ì„œ í´ë˜ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    raw_path = Path(raw_dir)
    classes = set()
    
    # train/test/val êµ¬ì¡° í™•ì¸
    for split in ['train', 'test', 'val']:
        split_path = raw_path / split
        if split_path.exists():
            for d in split_path.iterdir():
                if d.is_dir() and d.name.startswith('Beef_'):
                    classes.add(d.name)
    
    # ì§ì ‘ í´ë˜ìŠ¤ í´ë” í™•ì¸
    for d in raw_path.iterdir():
        if d.is_dir() and d.name.startswith('Beef_'):
            classes.add(d.name)
    
    return sorted(list(classes))


def get_next_dataset_number(data_dir: str) -> int:
    """ë‹¤ìŒ train_dataset_N ë²ˆí˜¸ ì°¾ê¸°"""
    data_path = Path(data_dir)
    existing = []
    
    for d in data_path.iterdir():
        if d.is_dir() and d.name.startswith('train_dataset_'):
            try:
                num = int(d.name.split('_')[-1])
                existing.append(num)
            except ValueError:
                pass
    
    return max(existing) + 1 if existing else 1


def split_from_raw(
    raw_dir: str,
    data_dir: str,
    samples_per_class: int = 100,
    train_ratio: float = 0.7,
    val_ratio: float = 0.15,
    test_ratio: float = 0.15,
    seed: int = 42,
    dataset_number: Optional[int] = None
) -> dict:
    """
    raw_datasetì—ì„œ ê· í˜• ë°ì´í„°ì…‹ ìƒì„± (ì´ë™ ë°©ì‹)
    
    Args:
        raw_dir: raw_dataset ê²½ë¡œ
        data_dir: data í´ë” ê²½ë¡œ (train_dataset_Nì´ ìƒì„±ë  ìœ„ì¹˜)
        samples_per_class: í´ë˜ìŠ¤ë‹¹ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸: 100)
        train_ratio: í•™ìŠµ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ 0.7)
        val_ratio: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ 0.15)
        test_ratio: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ 0.15)
        seed: ëœë¤ ì‹œë“œ
        dataset_number: ë°ì´í„°ì…‹ ë²ˆí˜¸ (Noneì´ë©´ ìë™ ì¦ê°€)
    """
    random.seed(seed)
    
    raw_path = Path(raw_dir)
    data_path = Path(data_dir)
    
    if not raw_path.exists():
        print(f"âŒ ì˜¤ë¥˜: {raw_path}ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return {}
    
    # í´ë˜ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    classes = get_classes_from_raw(raw_dir)
    if not classes:
        print(f"âŒ ì˜¤ë¥˜: raw_datasetì—ì„œ í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}
    
    print(f"\nğŸ“‚ raw_dataset í´ë˜ìŠ¤: {len(classes)}ê°œ")
    
    # í˜„ì¬ ì´ë¯¸ì§€ ìˆ˜ëŸ‰ í™•ì¸
    class_images = {}
    print(f"\n{'í´ë˜ìŠ¤':<25} {'í˜„ì¬ ìˆ˜ëŸ‰':>10}")
    print(f"{'-'*40}")
    
    for cls in classes:
        images = get_all_images_from_raw(raw_dir, cls)
        class_images[cls] = images
        print(f"{cls:<25} {len(images):>10}ì¥")
    
    # ìµœì†Œ ìˆ˜ëŸ‰ í™•ì¸
    min_count = min(len(imgs) for imgs in class_images.values())
    
    if min_count < samples_per_class:
        print(f"\nâš ï¸ ì¼ë¶€ í´ë˜ìŠ¤ê°€ {samples_per_class}ì¥ ë¯¸ë§Œì…ë‹ˆë‹¤.")
        print(f"   ìµœì†Œ ìˆ˜ëŸ‰: {min_count}ì¥")
        
        insufficient = [(cls, len(imgs)) for cls, imgs in class_images.items() if len(imgs) < samples_per_class]
        print(f"\n   ë¶€ì¡±í•œ í´ë˜ìŠ¤:")
        for cls, cnt in insufficient:
            print(f"   - {cls}: {cnt}ì¥ (ì¶”ê°€ í•„ìš”: {samples_per_class - cnt}ì¥)")
        
        user_input = input(f"\n{min_count}ì¥ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if user_input.lower() != 'y':
            print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return {}
        samples_per_class = min_count
    
    # ë°ì´í„°ì…‹ ë²ˆí˜¸ ê²°ì •
    if dataset_number is None:
        dataset_number = get_next_dataset_number(data_dir)
    
    output_name = f"train_dataset_{dataset_number}"
    output_path = data_path / output_name
    
    # ë¶„í•  ë¹„ìœ¨ ê³„ì‚°
    train_count = int(samples_per_class * train_ratio)
    val_count = int(samples_per_class * val_ratio)
    test_count = samples_per_class - train_count - val_count
    
    print(f"\nâš™ï¸ ë¶„í•  ì„¤ì •:")
    print(f"   - ì¶œë ¥ í´ë”: {output_name}")
    print(f"   - í´ë˜ìŠ¤ë‹¹ ì´ ìƒ˜í”Œ: {samples_per_class}ì¥")
    print(f"   - Train: {train_count}ì¥ ({train_ratio*100:.0f}%)")
    print(f"   - Val: {val_count}ì¥ ({val_ratio*100:.0f}%)")
    print(f"   - Test: {test_count}ì¥ ({test_ratio*100:.0f}%)")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    for split in ['train', 'val', 'test']:
        for cls in classes:
            (output_path / split / cls).mkdir(parents=True, exist_ok=True)
    
    # í†µê³„
    stats = {
        'dataset_name': output_name,
        'total_moved': 0,
        'remaining': {}
    }
    
    print(f"\n{'='*65}")
    print(f"{'í´ë˜ìŠ¤':<25} {'ì´ë™':>8} {'ë‚¨ì€ ìˆ˜ëŸ‰':>12} {'ìƒíƒœ':>10}")
    print(f"{'='*65}")
    
    for cls in classes:
        images = class_images[cls]
        random.shuffle(images)
        
        # ë¶„í• í•  ì´ë¯¸ì§€ ì„ íƒ
        selected = images[:samples_per_class]
        remaining = len(images) - samples_per_class
        
        train_imgs = selected[:train_count]
        val_imgs = selected[train_count:train_count + val_count]
        test_imgs = selected[train_count + val_count:]
        
        # ì´ë™ (move) - Train
        for i, img in enumerate(train_imgs):
            dst = output_path / 'train' / cls / f"{cls}_{i+1:04d}{img.suffix}"
            shutil.move(str(img), str(dst))
        
        # ì´ë™ (move) - Val
        for i, img in enumerate(val_imgs):
            dst = output_path / 'val' / cls / f"{cls}_{i+1:04d}{img.suffix}"
            shutil.move(str(img), str(dst))
        
        # ì´ë™ (move) - Test
        for i, img in enumerate(test_imgs):
            dst = output_path / 'test' / cls / f"{cls}_{i+1:04d}{img.suffix}"
            shutil.move(str(img), str(dst))
        
        stats['total_moved'] += samples_per_class
        stats['remaining'][cls] = remaining
        
        status = "âœ…" if remaining >= samples_per_class else f"ğŸ“‰ {remaining}ì¥"
        print(f"{cls:<25} {samples_per_class:>8} {remaining:>12} {status:>10}")
    
    print(f"{'='*65}")
    total_remaining = sum(stats['remaining'].values())
    print(f"{'í•©ê³„':<25} {stats['total_moved']:>8} {total_remaining:>12}")
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*65}")
    print(f"ğŸ“Š ë¶„í•  ì™„ë£Œ!")
    print(f"{'='*65}")
    print(f"   ğŸ“ ìƒì„±ëœ ë°ì´í„°ì…‹: {output_path}")
    print(f"   ğŸ“¦ ì´ë™ëœ ì´ë¯¸ì§€: {stats['total_moved']}ì¥")
    print(f"   ğŸ“‚ raw_dataset ë‚¨ì€ ì´ë¯¸ì§€: {total_remaining}ì¥")
    
    # ì¶”ê°€ ë¶„í•  ê°€ëŠ¥ ì—¬ë¶€
    min_remaining = min(stats['remaining'].values())
    possible_splits = min_remaining // samples_per_class
    if possible_splits > 0:
        print(f"\n   ğŸ’¡ ì¶”ê°€ ë¶„í•  ê°€ëŠ¥: {possible_splits}íšŒ (ê° {samples_per_class}ì¥ ê¸°ì¤€)")
    else:
        print(f"\n   âš ï¸ ì¶”ê°€ {samples_per_class}ì¥ ë¶„í•  ë¶ˆê°€ëŠ¥")
        if min_remaining > 0:
            print(f"      ìµœëŒ€ {min_remaining}ì¥ ê¸°ì¤€ìœ¼ë¡œ ë¶„í•  ê°€ëŠ¥")
    
    return stats


def check_raw_dataset(raw_dir: str):
    """raw_dataset í˜„í™© í™•ì¸"""
    raw_path = Path(raw_dir)
    
    if not raw_path.exists():
        print(f"âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {raw_dir}")
        return
    
    classes = get_classes_from_raw(raw_dir)
    
    print(f"\nğŸ“‚ raw_dataset: {raw_dir}")
    print(f"{'='*50}")
    print(f"{'í´ë˜ìŠ¤':<30} {'ì´ë¯¸ì§€ ìˆ˜':>15}")
    print(f"{'-'*50}")
    
    total = 0
    min_count = float('inf')
    
    for cls in classes:
        images = get_all_images_from_raw(raw_dir, cls)
        count = len(images)
        total += count
        min_count = min(min_count, count)
        print(f"{cls:<30} {count:>15}ì¥")
    
    print(f"{'-'*50}")
    print(f"{'í•©ê³„':<30} {total:>15}ì¥")
    print(f"{'ìµœì†Œ í´ë˜ìŠ¤ ìˆ˜ëŸ‰':<30} {min_count:>15}ì¥")
    
    # ë¶„í•  ê°€ëŠ¥ íšŸìˆ˜
    possible_100 = min_count // 100
    print(f"\nğŸ’¡ 100ì¥ ê¸°ì¤€ ë¶„í•  ê°€ëŠ¥ íšŸìˆ˜: {possible_100}íšŒ")


def main():
    parser = argparse.ArgumentParser(description='raw_dataset ê· í˜• ë¶„í•  ë„êµ¬')
    subparsers = parser.add_subparsers(dest='command', help='ì‹¤í–‰ ëª…ë ¹')
    
    # split ëª…ë ¹ - raw_datasetì—ì„œ ë¶„í• 
    split_parser = subparsers.add_parser('split', help='raw_datasetì—ì„œ ê· í˜• ë°ì´í„°ì…‹ ìƒì„±')
    split_parser.add_argument('--raw', '-r', default='../data/raw_dataset', help='raw_dataset ê²½ë¡œ (ê¸°ë³¸: ../data/raw_dataset)')
    split_parser.add_argument('--data', '-d', default='../data', help='data í´ë” ê²½ë¡œ (ê¸°ë³¸: ../data)')
    split_parser.add_argument('--samples', '-n', type=int, default=100, help='í´ë˜ìŠ¤ë‹¹ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸: 100)')
    split_parser.add_argument('--train-ratio', type=float, default=0.7, help='Train ë¹„ìœ¨ (ê¸°ë³¸: 0.7)')
    split_parser.add_argument('--val-ratio', type=float, default=0.15, help='Val ë¹„ìœ¨ (ê¸°ë³¸: 0.15)')
    split_parser.add_argument('--seed', type=int, default=42, help='ëœë¤ ì‹œë“œ (ê¸°ë³¸: 42)')
    split_parser.add_argument('--number', type=int, default=None, help='ë°ì´í„°ì…‹ ë²ˆí˜¸ (ê¸°ë³¸: ìë™)')
    
    # check ëª…ë ¹ - raw_dataset í˜„í™© í™•ì¸
    check_parser = subparsers.add_parser('check', help='raw_dataset í˜„í™© í™•ì¸')
    check_parser.add_argument('--raw', '-r', default='../data/raw_dataset', help='raw_dataset ê²½ë¡œ')
    
    # status ëª…ë ¹ - ì „ì²´ ë°ì´í„°ì…‹ í˜„í™©
    status_parser = subparsers.add_parser('status', help='ì „ì²´ ë°ì´í„°ì…‹ í˜„í™© í™•ì¸')
    status_parser.add_argument('--data', '-d', default='../data', help='data í´ë” ê²½ë¡œ')
    
    args = parser.parse_args()
    
    if args.command == 'split':
        test_ratio = 1.0 - args.train_ratio - args.val_ratio
        split_from_raw(
            raw_dir=args.raw,
            data_dir=args.data,
            samples_per_class=args.samples,
            train_ratio=args.train_ratio,
            val_ratio=args.val_ratio,
            test_ratio=test_ratio,
            seed=args.seed,
            dataset_number=args.number
        )
    
    elif args.command == 'check':
        check_raw_dataset(args.raw)
    
    elif args.command == 'status':
        show_all_datasets(args.data)
    
    else:
        parser.print_help()


def show_all_datasets(data_dir: str):
    """ëª¨ë“  ë°ì´í„°ì…‹ í˜„í™© í‘œì‹œ"""
    data_path = Path(data_dir)
    
    print(f"\nğŸ“Š ë°ì´í„°ì…‹ í˜„í™©: {data_path}")
    print(f"{'='*60}")
    
    # raw_dataset í™•ì¸
    raw_path = data_path / 'raw_dataset'
    if raw_path.exists():
        classes = get_classes_from_raw(str(raw_path))
        total = sum(len(get_all_images_from_raw(str(raw_path), cls)) for cls in classes)
        min_count = min(len(get_all_images_from_raw(str(raw_path), cls)) for cls in classes) if classes else 0
        print(f"\nğŸ“ raw_dataset")
        print(f"   ì´ ì´ë¯¸ì§€: {total}ì¥ | ìµœì†Œ í´ë˜ìŠ¤: {min_count}ì¥")
        print(f"   100ì¥ ë¶„í•  ê°€ëŠ¥: {min_count // 100}íšŒ")
    
    # train_dataset_N í™•ì¸
    datasets = sorted([d for d in data_path.iterdir() 
                      if d.is_dir() and d.name.startswith('train_dataset_')])
    
    if datasets:
        print(f"\nğŸ“ ë¶„í• ëœ ë°ì´í„°ì…‹:")
        for ds in datasets:
            train_path = ds / 'train'
            if train_path.exists():
                classes = [d for d in train_path.iterdir() if d.is_dir()]
                total = sum(len(list((ds / split / cls.name).iterdir())) 
                           for split in ['train', 'val', 'test'] 
                           for cls in classes 
                           if (ds / split / cls.name).exists())
                print(f"   - {ds.name}: {total}ì¥ ({len(classes)} í´ë˜ìŠ¤)")


def check_dataset(path: str):
    """ë°ì´í„°ì…‹ í˜„í™© í™•ì¸"""
    dataset_path = Path(path)
    
    if not dataset_path.exists():
        print(f"âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}")
        return
    
    # train/val/test êµ¬ì¡°ì¸ì§€ í™•ì¸
    splits = ['train', 'val', 'test']
    has_splits = all((dataset_path / s).exists() for s in splits)
    
    if has_splits:
        print(f"\nğŸ“‚ ë°ì´í„°ì…‹: {path}")
        print(f"{'='*70}")
        
        # í´ë˜ìŠ¤ ëª©ë¡
        classes = sorted([d.name for d in (dataset_path / 'train').iterdir() if d.is_dir()])
        
        print(f"{'í´ë˜ìŠ¤':<25} {'Train':>10} {'Val':>10} {'Test':>10} {'Total':>10}")
        print(f"{'-'*70}")
        
        totals = {'train': 0, 'val': 0, 'test': 0}
        
        for cls in classes:
            counts = {}
            for split in splits:
                cls_path = dataset_path / split / cls
                if cls_path.exists():
                    count = len([f for f in cls_path.iterdir() if f.is_file()])
                else:
                    count = 0
                counts[split] = count
                totals[split] += count
            
            total = sum(counts.values())
            print(f"{cls:<25} {counts['train']:>10} {counts['val']:>10} {counts['test']:>10} {total:>10}")
        
        print(f"{'-'*70}")
        print(f"{'í•©ê³„':<25} {totals['train']:>10} {totals['val']:>10} {totals['test']:>10} {sum(totals.values()):>10}")
    
    else:
        # ë‹¨ìˆœ í´ë˜ìŠ¤ í´ë” êµ¬ì¡°
        print(f"\nğŸ“‚ í´ë”: {path}")
        print(f"{'='*50}")
        
        classes = sorted([d.name for d in dataset_path.iterdir() if d.is_dir()])
        
        print(f"{'í´ë˜ìŠ¤':<35} {'ì´ë¯¸ì§€ ìˆ˜':>10}")
        print(f"{'-'*50}")
        
        total = 0
        for cls in classes:
            cls_path = dataset_path / cls
            count = len([f for f in cls_path.iterdir() if f.is_file()])
            total += count
            print(f"{cls:<35} {count:>10}")
        
        print(f"{'-'*50}")
        print(f"{'í•©ê³„':<35} {total:>10}")


if __name__ == '__main__':
    main()
